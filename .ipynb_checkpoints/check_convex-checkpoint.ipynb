{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from algos.convex_naf import ConvexNAFAlgorithm\n",
    "from algos.ddpg import DDPG as MyDDPG\n",
    "from qfunctions.convex_naf_qfunction import ConcaveNAF\n",
    "from qfunctions.nn_qfunction import FeedForwardCritic\n",
    "from qfunctions.quadratic_naf_qfunction import QuadraticNAF\n",
    "from qfunctions.quadratic_qf import QuadraticQF\n",
    "from policies.nn_policy import FeedForwardPolicy\n",
    "from rllab.exploration_strategies.ou_strategy import OUStrategy\n",
    "\n",
    "from rllab.envs.box2d.cartpole_env import CartpoleEnv\n",
    "from rllab.envs.normalized_env import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10\n",
    "EPOCH_LENGTH = 100\n",
    "EVAL_SAMPLES = 100\n",
    "DISCOUNT = 0.99\n",
    "QF_LEARNING_RATE = 1e-3\n",
    "POLICY_LEARNING_RATE = 1e-4\n",
    "BATCH_LEARNING_RATE = 1e-2\n",
    "SOFT_TARGET_TAU = 1e-2\n",
    "REPLAY_POOL_SIZE = 1000000\n",
    "MIN_POOL_SIZE = 256\n",
    "SCALE_REWARD = 1.0\n",
    "QF_WEIGHT_DECAY = 0.01\n",
    "MAX_PATH_LENGTH = 1000\n",
    "N_UPDATES_PER_TIME_STEP = 5\n",
    "\n",
    "QF_TYPE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArgmaxPolicy' object has no attribute 'qf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4adeaed95f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mqf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;34m**\u001b[0m\u001b[0malgo_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m )\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/naf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, exploration_strategy, naf_qfunction, qf_learning_rate, qf_weight_decay, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mexploration_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexploration_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/online_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, policy, exploration_strategy, batch_size, n_epochs, epoch_length, min_pool_size, replay_pool_size, discount, soft_target_tau, max_path_length, eval_samples, scale_reward, render, n_updates_per_time_step)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_tensorflow_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes_path_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/convex_naf.py\u001b[0m in \u001b[0;36m_init_tensorflow_ops\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_tensorflow_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_tensorflow_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_af\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         self._clip_weight_ops = [v.assign(tf.maximum(v, 0)) for v in\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/naf.py\u001b[0m in \u001b[0;36m_init_tensorflow_ops\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicit_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_vf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_qf_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/qfunctions/convex_naf_qfunction.py\u001b[0m in \u001b[0;36mimplicit_policy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimplicit_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantage_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicit_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/qfunctions/action_concave_qfunction.py\u001b[0m in \u001b[0;36mimplicit_policy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m             self._sgd_policy = ArgmaxPolicy(\n\u001b[1;32m    113\u001b[0m                 \u001b[0mname_or_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"argmax_policy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mqfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             )\n\u001b[1;32m    116\u001b[0m             self._bundle_policy = BundleEntropyArgmaxPolicy(\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/policies/argmax_policy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_scope, qfunction, learning_rate, n_update_steps, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                     var_list=[self.proposed_action])\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# self.clipped_action = tf.clip_by_value(self.proposed_action, -1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 self.process_action = self.qf.action_input_preprocess(\n\u001b[0m\u001b[1;32m     74\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposed_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ArgmaxPolicy' object has no attribute 'qf'"
     ]
    }
   ],
   "source": [
    "env = normalize(CartpoleEnv())\n",
    "policy_params = dict(\n",
    "    observation_hidden_sizes=(100, 100),\n",
    "    hidden_nonlinearity=tf.nn.relu,\n",
    "    output_nonlinearity=tf.nn.tanh,\n",
    ")\n",
    "algo_params = dict(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    epoch_length=EPOCH_LENGTH,\n",
    "    eval_samples=EVAL_SAMPLES,\n",
    "    discount=DISCOUNT,\n",
    "#     policy_learning_rate=POLICY_LEARNING_RATE,\n",
    "    qf_learning_rate=QF_LEARNING_RATE,\n",
    "    soft_target_tau=SOFT_TARGET_TAU,\n",
    "    replay_pool_size=REPLAY_POOL_SIZE,\n",
    "    min_pool_size=MIN_POOL_SIZE,\n",
    "    scale_reward=SCALE_REWARD,\n",
    "    max_path_length=MAX_PATH_LENGTH,\n",
    "    qf_weight_decay=QF_WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "es = OUStrategy(env_spec=env.spec)\n",
    "# policy = FeedForwardPolicy(\n",
    "#     name_or_scope=\"policy\",\n",
    "#     env_spec=env.spec,\n",
    "#     **policy_params\n",
    "# )\n",
    "# qf = QuadraticNAF(\n",
    "#     name_or_scope=\"quadratic_qfunction\",\n",
    "#     env_spec=env.spec,\n",
    "# )\n",
    "# qf = FeedForwardCritic(\n",
    "#     name_or_scope=\"feed_forward_qfunction\",\n",
    "#     env_spec=env.spec,\n",
    "# )\n",
    "# algorithm = MyDDPG(\n",
    "#     env,\n",
    "#     es,\n",
    "#     policy,\n",
    "#     qf,\n",
    "#     **algo_params\n",
    "# )\n",
    "\n",
    "optimizer_type = 'sgd'\n",
    "qf = ConcaveNAF(\n",
    "    name_or_scope=\"qf\",\n",
    "    env_spec=env.spec,\n",
    "    optimizer_type=optimizer_type,\n",
    ")\n",
    "algorithm = ConvexNAFAlgorithm(\n",
    "    env,\n",
    "    es,\n",
    "    qf,\n",
    "    **algo_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policy = qf.implicit_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:11:27.392939 PST | Populating workers...\n",
      "2016-12-16 06:11:27.394848 PST | Populated\n",
      "2016-12-16 06:11:27.396694 PST | Epoch #0 | Training started\n",
      "2016-12-16 06:11:32.748808 PST | Epoch #0 | Training finished. Time: 5.350584030151367\n",
      "2016-12-16 06:11:32.750002 PST | Epoch #1 | Training started\n",
      "2016-12-16 06:11:38.340984 PST | Epoch #1 | Training finished. Time: 5.589614152908325\n",
      "2016-12-16 06:11:38.342405 PST | Epoch #1 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:11:50.439447 PST | Epoch #1 | Eval time: 12.097042083740234\n",
      "2016-12-16 06:11:50.442927 PST | ---------------------  -------------\n",
      "2016-12-16 06:11:50.444591 PST | Epoch                    1\n",
      "2016-12-16 06:11:50.445967 PST | AverageReturn           77.4438\n",
      "2016-12-16 06:11:50.447553 PST | QfLoss                  88.0462\n",
      "2016-12-16 06:11:50.449389 PST | YsMean                   8.85029\n",
      "2016-12-16 06:11:50.450570 PST | YsStd                    3.17912\n",
      "2016-12-16 06:11:50.452936 PST | YsMax                    9.99881\n",
      "2016-12-16 06:11:50.454689 PST | YsMin                    0\n",
      "2016-12-16 06:11:50.457363 PST | QfOutputMean             0.0240481\n",
      "2016-12-16 06:11:50.463803 PST | QfOutputStd              0.0087723\n",
      "2016-12-16 06:11:50.467639 PST | QfOutputMax              0.0478853\n",
      "2016-12-16 06:11:50.472722 PST | QfOutputMin              0.0117025\n",
      "2016-12-16 06:11:50.479398 PST | TargetVfOutputMean      -0.000516322\n",
      "2016-12-16 06:11:50.482022 PST | TargetVfOutputStd        0.000262916\n",
      "2016-12-16 06:11:50.485485 PST | TargetVfOutputMax        0.000186769\n",
      "2016-12-16 06:11:50.491728 PST | TargetVfOutputMin       -0.000891475\n",
      "2016-12-16 06:11:50.498146 PST | RewardsMean              8.85072\n",
      "2016-12-16 06:11:50.504385 PST | RewardsStd               3.17928\n",
      "2016-12-16 06:11:50.508577 PST | RewardsMax               9.9996\n",
      "2016-12-16 06:11:50.513662 PST | RewardsMin               0\n",
      "2016-12-16 06:11:50.514643 PST | ReturnsMean             77.4438\n",
      "2016-12-16 06:11:50.517307 PST | ReturnsStd              25.855\n",
      "2016-12-16 06:11:50.519313 PST | ReturnsMax             139.931\n",
      "2016-12-16 06:11:50.522104 PST | ReturnsMin              39.9648\n",
      "2016-12-16 06:11:50.523219 PST | DiscountedReturnsMean   74.5701\n",
      "2016-12-16 06:11:50.525500 PST | DiscountedReturnsStd    23.7937\n",
      "2016-12-16 06:11:50.527009 PST | DiscountedReturnsMax   131.192\n",
      "2016-12-16 06:11:50.528683 PST | DiscountedReturnsMin    39.3695\n",
      "2016-12-16 06:11:50.530111 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:11:50.531437 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:11:50.532969 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:11:50.534349 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:11:50.535956 PST | TrainingReturnsMean     23.3731\n",
      "2016-12-16 06:11:50.537244 PST | TrainingReturnsStd      12.4301\n",
      "2016-12-16 06:11:50.538284 PST | TrainingReturnsMax      59.964\n",
      "2016-12-16 06:11:50.539774 PST | TrainingReturnsMin       0\n",
      "2016-12-16 06:11:50.542005 PST | ---------------------  -------------\n",
      "2016-12-16 06:11:50.543678 PST | Epoch #2 | Training started\n",
      "2016-12-16 06:11:57.388970 PST | Epoch #2 | Training finished. Time: 6.844283103942871\n",
      "2016-12-16 06:11:57.391216 PST | Epoch #2 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:12:12.855256 PST | Epoch #2 | Eval time: 15.464191913604736\n",
      "2016-12-16 06:12:12.858948 PST | ---------------------  ----------\n",
      "2016-12-16 06:12:12.860839 PST | Epoch                    2\n",
      "2016-12-16 06:12:12.862474 PST | AverageReturn           90.8576\n",
      "2016-12-16 06:12:12.863831 PST | QfLoss                  14.8066\n",
      "2016-12-16 06:12:12.865442 PST | YsMean                  10.3635\n",
      "2016-12-16 06:12:12.866986 PST | YsStd                    3.45878\n",
      "2016-12-16 06:12:12.868756 PST | YsMax                   12.6864\n",
      "2016-12-16 06:12:12.871941 PST | YsMin                    0\n",
      "2016-12-16 06:12:12.878457 PST | QfOutputMean            11.0058\n",
      "2016-12-16 06:12:12.880005 PST | QfOutputStd              1.25896\n",
      "2016-12-16 06:12:12.881543 PST | QfOutputMax             13.5204\n",
      "2016-12-16 06:12:12.883046 PST | QfOutputMin              8.07924\n",
      "2016-12-16 06:12:12.884469 PST | TargetVfOutputMean       1.48352\n",
      "2016-12-16 06:12:12.886052 PST | TargetVfOutputStd        0.411799\n",
      "2016-12-16 06:12:12.887213 PST | TargetVfOutputMax        2.73209\n",
      "2016-12-16 06:12:12.889041 PST | TargetVfOutputMin        1.00934\n",
      "2016-12-16 06:12:12.890807 PST | RewardsMean              9.00391\n",
      "2016-12-16 06:12:12.892126 PST | RewardsStd               2.98626\n",
      "2016-12-16 06:12:12.893417 PST | RewardsMax              10\n",
      "2016-12-16 06:12:12.894675 PST | RewardsMin               0\n",
      "2016-12-16 06:12:12.896448 PST | ReturnsMean             90.8576\n",
      "2016-12-16 06:12:12.898406 PST | ReturnsStd              51.6017\n",
      "2016-12-16 06:12:12.904311 PST | ReturnsMax             179.954\n",
      "2016-12-16 06:12:12.910717 PST | ReturnsMin              29.9498\n",
      "2016-12-16 06:12:12.915915 PST | DiscountedReturnsMean   86.0517\n",
      "2016-12-16 06:12:12.921384 PST | DiscountedReturnsStd    46.7547\n",
      "2016-12-16 06:12:12.928851 PST | DiscountedReturnsMax   165.447\n",
      "2016-12-16 06:12:12.931295 PST | DiscountedReturnsMin    29.6514\n",
      "2016-12-16 06:12:12.934048 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:12:12.935502 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:12:12.936894 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:12:12.939203 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:12:12.940840 PST | TrainingReturnsMean     63.5339\n",
      "2016-12-16 06:12:12.943287 PST | TrainingReturnsStd      45.904\n",
      "2016-12-16 06:12:12.944413 PST | TrainingReturnsMax     159.889\n",
      "2016-12-16 06:12:12.946850 PST | TrainingReturnsMin       9.98682\n",
      "2016-12-16 06:12:12.948954 PST | ---------------------  ----------\n",
      "2016-12-16 06:12:12.951415 PST | Epoch #3 | Training started\n",
      "2016-12-16 06:12:21.319901 PST | Epoch #3 | Training finished. Time: 8.366887092590332\n",
      "2016-12-16 06:12:21.321386 PST | Epoch #3 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:12:39.644959 PST | Epoch #3 | Eval time: 18.323570013046265\n",
      "2016-12-16 06:12:39.648191 PST | ---------------------  ----------\n",
      "2016-12-16 06:12:39.649528 PST | Epoch                    3\n",
      "2016-12-16 06:12:39.651133 PST | AverageReturn           74.941\n",
      "2016-12-16 06:12:39.652556 PST | QfLoss                  23.0473\n",
      "2016-12-16 06:12:39.654074 PST | YsMean                  14.4688\n",
      "2016-12-16 06:12:39.655474 PST | YsStd                    5.3666\n",
      "2016-12-16 06:12:39.656948 PST | YsMax                   18.2828\n",
      "2016-12-16 06:12:39.658241 PST | YsMin                    0\n",
      "2016-12-16 06:12:39.659639 PST | QfOutputMean            14.8163\n",
      "2016-12-16 06:12:39.660923 PST | QfOutputStd              1.76612\n",
      "2016-12-16 06:12:39.662420 PST | QfOutputMax             17.5553\n",
      "2016-12-16 06:12:39.663784 PST | QfOutputMin              9.4017\n",
      "2016-12-16 06:12:39.666543 PST | TargetVfOutputMean       6.47759\n",
      "2016-12-16 06:12:39.670246 PST | TargetVfOutputStd        0.951351\n",
      "2016-12-16 06:12:39.675280 PST | TargetVfOutputMax        8.38525\n",
      "2016-12-16 06:12:39.679842 PST | TargetVfOutputMin        4.40385\n",
      "2016-12-16 06:12:39.686077 PST | RewardsMean              8.81659\n",
      "2016-12-16 06:12:39.696722 PST | RewardsStd               3.21937\n",
      "2016-12-16 06:12:39.702417 PST | RewardsMax               9.99975\n",
      "2016-12-16 06:12:39.708430 PST | RewardsMin               0\n",
      "2016-12-16 06:12:39.713026 PST | ReturnsMean             74.941\n",
      "2016-12-16 06:12:39.734100 PST | ReturnsStd              29.8543\n",
      "2016-12-16 06:12:39.735479 PST | ReturnsMax             129.946\n",
      "2016-12-16 06:12:39.736711 PST | ReturnsMin              19.9633\n",
      "2016-12-16 06:12:39.737964 PST | DiscountedReturnsMean   72.1327\n",
      "2016-12-16 06:12:39.740897 PST | DiscountedReturnsStd    27.8409\n",
      "2016-12-16 06:12:39.743599 PST | DiscountedReturnsMax   122.43\n",
      "2016-12-16 06:12:39.745745 PST | DiscountedReturnsMin    19.8635\n",
      "2016-12-16 06:12:39.747189 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:12:39.748546 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:12:39.749974 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:12:39.752144 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:12:39.753001 PST | TrainingReturnsMean     55.2968\n",
      "2016-12-16 06:12:39.754170 PST | TrainingReturnsStd      35.5459\n",
      "2016-12-16 06:12:39.755643 PST | TrainingReturnsMax     149.905\n",
      "2016-12-16 06:12:39.756824 PST | TrainingReturnsMin       9.98127\n",
      "2016-12-16 06:12:39.758216 PST | ---------------------  ----------\n",
      "2016-12-16 06:12:39.759651 PST | Epoch #4 | Training started\n",
      "2016-12-16 06:12:49.167275 PST | Epoch #4 | Training finished. Time: 9.406564950942993\n",
      "2016-12-16 06:12:49.168592 PST | Epoch #4 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:13:07.612561 PST | Epoch #4 | Eval time: 18.443989992141724\n",
      "2016-12-16 06:13:07.614523 PST | ---------------------  ---------\n",
      "2016-12-16 06:13:07.616170 PST | Epoch                    4\n",
      "2016-12-16 06:13:07.617735 PST | AverageReturn           73.2742\n",
      "2016-12-16 06:13:07.619117 PST | QfLoss                  33.7721\n",
      "2016-12-16 06:13:07.621236 PST | YsMean                  19.1322\n",
      "2016-12-16 06:13:07.622540 PST | YsStd                    7.19284\n",
      "2016-12-16 06:13:07.623913 PST | YsMax                   24.9877\n",
      "2016-12-16 06:13:07.625354 PST | YsMin                    0\n",
      "2016-12-16 06:13:07.626881 PST | QfOutputMean            17.4873\n",
      "2016-12-16 06:13:07.628432 PST | QfOutputStd              2.96536\n",
      "2016-12-16 06:13:07.629956 PST | QfOutputMax             23.329\n",
      "2016-12-16 06:13:07.631390 PST | QfOutputMin              9.40126\n",
      "2016-12-16 06:13:07.632966 PST | TargetVfOutputMean      12.0274\n",
      "2016-12-16 06:13:07.634105 PST | TargetVfOutputStd        1.42804\n",
      "2016-12-16 06:13:07.635496 PST | TargetVfOutputMax       15.1512\n",
      "2016-12-16 06:13:07.637035 PST | TargetVfOutputMin        7.20712\n",
      "2016-12-16 06:13:07.638955 PST | RewardsMean              8.79291\n",
      "2016-12-16 06:13:07.640593 PST | RewardsStd               3.247\n",
      "2016-12-16 06:13:07.642786 PST | RewardsMax               9.99966\n",
      "2016-12-16 06:13:07.644179 PST | RewardsMin               0\n",
      "2016-12-16 06:13:07.645541 PST | ReturnsMean             73.2742\n",
      "2016-12-16 06:13:07.648286 PST | ReturnsStd              36.1264\n",
      "2016-12-16 06:13:07.649652 PST | ReturnsMax             129.939\n",
      "2016-12-16 06:13:07.651232 PST | ReturnsMin              19.9662\n",
      "2016-12-16 06:13:07.652770 PST | DiscountedReturnsMean   70.3852\n",
      "2016-12-16 06:13:07.654435 PST | DiscountedReturnsStd    33.5501\n",
      "2016-12-16 06:13:07.656042 PST | DiscountedReturnsMax   122.423\n",
      "2016-12-16 06:13:07.658368 PST | DiscountedReturnsMin    19.8664\n",
      "2016-12-16 06:13:07.659836 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:13:07.661358 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:13:07.663028 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:13:07.664570 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:13:07.665831 PST | TrainingReturnsMean     55.2993\n",
      "2016-12-16 06:13:07.667195 PST | TrainingReturnsStd      40.2959\n",
      "2016-12-16 06:13:07.668435 PST | TrainingReturnsMax     179.921\n",
      "2016-12-16 06:13:07.670440 PST | TrainingReturnsMin      19.9704\n",
      "2016-12-16 06:13:07.672309 PST | ---------------------  ---------\n",
      "2016-12-16 06:13:07.673792 PST | Epoch #5 | Training started\n",
      "2016-12-16 06:13:17.585622 PST | Epoch #5 | Training finished. Time: 9.910341024398804\n",
      "2016-12-16 06:13:17.586787 PST | Epoch #5 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:13:38.817934 PST | Epoch #5 | Eval time: 21.23113489151001\n",
      "2016-12-16 06:13:38.820722 PST | ---------------------  ---------\n",
      "2016-12-16 06:13:38.822156 PST | Epoch                    5\n",
      "2016-12-16 06:13:38.823518 PST | AverageReturn          101.055\n",
      "2016-12-16 06:13:38.824662 PST | QfLoss                  28.2077\n",
      "2016-12-16 06:13:38.825800 PST | YsMean                  24.2602\n",
      "2016-12-16 06:13:38.826944 PST | YsStd                    8.18322\n",
      "2016-12-16 06:13:38.828220 PST | YsMax                   31.4696\n",
      "2016-12-16 06:13:38.829416 PST | YsMin                    0\n",
      "2016-12-16 06:13:38.830698 PST | QfOutputMean            21.7205\n",
      "2016-12-16 06:13:38.831877 PST | QfOutputStd              5.40554\n",
      "2016-12-16 06:13:38.833061 PST | QfOutputMax             28.6864\n",
      "2016-12-16 06:13:38.834251 PST | QfOutputMin              8.70546\n",
      "2016-12-16 06:13:38.835485 PST | TargetVfOutputMean      17.1014\n",
      "2016-12-16 06:13:38.836767 PST | TargetVfOutputStd        3.10451\n",
      "2016-12-16 06:13:38.838000 PST | TargetVfOutputMax       21.6983\n",
      "2016-12-16 06:13:38.839197 PST | TargetVfOutputMin        8.72667\n",
      "2016-12-16 06:13:38.840402 PST | RewardsMean              9.09499\n",
      "2016-12-16 06:13:38.841896 PST | RewardsStd               2.86025\n",
      "2016-12-16 06:13:38.843295 PST | RewardsMax              10\n",
      "2016-12-16 06:13:38.844878 PST | RewardsMin               0\n",
      "2016-12-16 06:13:38.846533 PST | ReturnsMean            101.055\n",
      "2016-12-16 06:13:38.848003 PST | ReturnsStd              51.9497\n",
      "2016-12-16 06:13:38.849443 PST | ReturnsMax             209.953\n",
      "2016-12-16 06:13:38.850958 PST | ReturnsMin              39.9454\n",
      "2016-12-16 06:13:38.852458 PST | DiscountedReturnsMean   95.3619\n",
      "2016-12-16 06:13:38.853750 PST | DiscountedReturnsStd    46.1683\n",
      "2016-12-16 06:13:38.855280 PST | DiscountedReturnsMax   190.233\n",
      "2016-12-16 06:13:38.856813 PST | DiscountedReturnsMin    39.3503\n",
      "2016-12-16 06:13:38.858296 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:13:38.859586 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:13:38.861019 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:13:38.862611 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:13:38.864254 PST | TrainingReturnsMean     80.8643\n",
      "2016-12-16 06:13:38.865847 PST | TrainingReturnsStd      21.5071\n",
      "2016-12-16 06:13:38.867112 PST | TrainingReturnsMax     109.96\n",
      "2016-12-16 06:13:38.868514 PST | TrainingReturnsMin      39.9643\n",
      "2016-12-16 06:13:38.869798 PST | ---------------------  ---------\n",
      "2016-12-16 06:13:38.871013 PST | Epoch #6 | Training started\n",
      "2016-12-16 06:13:51.867628 PST | Epoch #6 | Training finished. Time: 12.994948863983154\n",
      "2016-12-16 06:13:51.869062 PST | Epoch #6 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:14:19.626079 PST | Epoch #6 | Eval time: 27.75701379776001\n",
      "2016-12-16 06:14:19.627816 PST | ---------------------  ---------\n",
      "2016-12-16 06:14:19.631290 PST | Epoch                    6\n",
      "2016-12-16 06:14:19.632754 PST | AverageReturn          105.501\n",
      "2016-12-16 06:14:19.635057 PST | QfLoss                  31.1713\n",
      "2016-12-16 06:14:19.636499 PST | YsMean                  27.5951\n",
      "2016-12-16 06:14:19.639670 PST | YsStd                    9.73921\n",
      "2016-12-16 06:14:19.641138 PST | YsMax                   37.4868\n",
      "2016-12-16 06:14:19.642944 PST | YsMin                    0\n",
      "2016-12-16 06:14:19.644776 PST | QfOutputMean            23.9919\n",
      "2016-12-16 06:14:19.647702 PST | QfOutputStd              7.4655\n",
      "2016-12-16 06:14:19.649939 PST | QfOutputMax             35.4622\n",
      "2016-12-16 06:14:19.651384 PST | QfOutputMin              4.83256\n",
      "2016-12-16 06:14:19.653031 PST | TargetVfOutputMean      20.9031\n",
      "2016-12-16 06:14:19.662303 PST | TargetVfOutputStd        5.06059\n",
      "2016-12-16 06:14:19.664202 PST | TargetVfOutputMax       27.7701\n",
      "2016-12-16 06:14:19.665311 PST | TargetVfOutputMin        6.58371\n",
      "2016-12-16 06:14:19.667178 PST | RewardsMean              9.1299\n",
      "2016-12-16 06:14:19.668797 PST | RewardsStd               2.81013\n",
      "2016-12-16 06:14:19.670071 PST | RewardsMax              10\n",
      "2016-12-16 06:14:19.671495 PST | RewardsMin               0\n",
      "2016-12-16 06:14:19.672812 PST | ReturnsMean            105.501\n",
      "2016-12-16 06:14:19.675190 PST | ReturnsStd              59.8379\n",
      "2016-12-16 06:14:19.676872 PST | ReturnsMax             259.955\n",
      "2016-12-16 06:14:19.678244 PST | ReturnsMin              29.9523\n",
      "2016-12-16 06:14:19.679997 PST | DiscountedReturnsMean   99.0284\n",
      "2016-12-16 06:14:19.681822 PST | DiscountedReturnsStd    51.5694\n",
      "2016-12-16 06:14:19.683203 PST | DiscountedReturnsMax   229.92\n",
      "2016-12-16 06:14:19.685947 PST | DiscountedReturnsMin    29.6538\n",
      "2016-12-16 06:14:19.695592 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:14:19.698650 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:14:19.700151 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:14:19.701375 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:14:19.703878 PST | TrainingReturnsMean     54.9635\n",
      "2016-12-16 06:14:19.705161 PST | TrainingReturnsStd      50.4562\n",
      "2016-12-16 06:14:19.706920 PST | TrainingReturnsMax     239.802\n",
      "2016-12-16 06:14:19.708147 PST | TrainingReturnsMin      19.9763\n",
      "2016-12-16 06:14:19.709771 PST | ---------------------  ---------\n",
      "2016-12-16 06:14:19.711961 PST | Epoch #7 | Training started\n",
      "2016-12-16 06:14:31.551535 PST | Epoch #7 | Training finished. Time: 11.838194131851196\n",
      "2016-12-16 06:14:31.552765 PST | Epoch #7 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:15:05.371421 PST | Epoch #7 | Eval time: 33.81864881515503\n",
      "2016-12-16 06:15:05.385115 PST | ---------------------  ---------\n",
      "2016-12-16 06:15:05.388362 PST | Epoch                    7\n",
      "2016-12-16 06:15:05.399726 PST | AverageReturn           90.9442\n",
      "2016-12-16 06:15:05.404328 PST | QfLoss                  31.7837\n",
      "2016-12-16 06:15:05.406730 PST | YsMean                  29.7737\n",
      "2016-12-16 06:15:05.419769 PST | YsStd                   12.1055\n",
      "2016-12-16 06:15:05.421201 PST | YsMax                   43.6175\n",
      "2016-12-16 06:15:05.422931 PST | YsMin                    0\n",
      "2016-12-16 06:15:05.429811 PST | QfOutputMean            26.028\n",
      "2016-12-16 06:15:05.432989 PST | QfOutputStd              9.41728\n",
      "2016-12-16 06:15:05.436206 PST | QfOutputMax             39.2785\n",
      "2016-12-16 06:15:05.437553 PST | QfOutputMin              5.65145\n",
      "2016-12-16 06:15:05.439086 PST | TargetVfOutputMean      24.0674\n",
      "2016-12-16 06:15:05.440821 PST | TargetVfOutputStd        7.45987\n",
      "2016-12-16 06:15:05.444942 PST | TargetVfOutputMax       33.969\n",
      "2016-12-16 06:15:05.447740 PST | TargetVfOutputMin        6.64471\n",
      "2016-12-16 06:15:05.450123 PST | RewardsMean              9.00438\n",
      "2016-12-16 06:15:05.451600 PST | RewardsStd               2.98493\n",
      "2016-12-16 06:15:05.453314 PST | RewardsMax              10\n",
      "2016-12-16 06:15:05.455099 PST | RewardsMin               0\n",
      "2016-12-16 06:15:05.456533 PST | ReturnsMean             90.9442\n",
      "2016-12-16 06:15:05.458005 PST | ReturnsStd              35.3407\n",
      "2016-12-16 06:15:05.463505 PST | ReturnsMax             159.95\n",
      "2016-12-16 06:15:05.466149 PST | ReturnsMin              49.9312\n",
      "2016-12-16 06:15:05.469070 PST | DiscountedReturnsMean   86.7759\n",
      "2016-12-16 06:15:05.470606 PST | DiscountedReturnsStd    32.1049\n",
      "2016-12-16 06:15:05.473379 PST | DiscountedReturnsMax   148.499\n",
      "2016-12-16 06:15:05.476845 PST | DiscountedReturnsMin    48.9427\n",
      "2016-12-16 06:15:05.480458 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:15:05.483436 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:15:05.486337 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:15:05.487963 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:15:05.489719 PST | TrainingReturnsMean     49.3394\n",
      "2016-12-16 06:15:05.492585 PST | TrainingReturnsStd      25.6042\n",
      "2016-12-16 06:15:05.494926 PST | TrainingReturnsMax      99.9563\n",
      "2016-12-16 06:15:05.498895 PST | TrainingReturnsMin       9.98168\n",
      "2016-12-16 06:15:05.501906 PST | ---------------------  ---------\n",
      "2016-12-16 06:15:05.503585 PST | Epoch #8 | Training started\n",
      "2016-12-16 06:15:21.520942 PST | Epoch #8 | Training finished. Time: 16.01496386528015\n",
      "2016-12-16 06:15:21.522211 PST | Epoch #8 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:15:50.739205 PST | Epoch #8 | Eval time: 29.216986894607544\n",
      "2016-12-16 06:15:50.741683 PST | ---------------------  ---------\n",
      "2016-12-16 06:15:50.743384 PST | Epoch                    8\n",
      "2016-12-16 06:15:50.745040 PST | AverageReturn          133.704\n",
      "2016-12-16 06:15:50.746618 PST | QfLoss                  39.3503\n",
      "2016-12-16 06:15:50.748020 PST | YsMean                  34.8683\n",
      "2016-12-16 06:15:50.749800 PST | YsStd                   12.6825\n",
      "2016-12-16 06:15:50.751252 PST | YsMax                   47.2845\n",
      "2016-12-16 06:15:50.752838 PST | YsMin                    0\n",
      "2016-12-16 06:15:50.754522 PST | QfOutputMean            30.2659\n",
      "2016-12-16 06:15:50.756276 PST | QfOutputStd             10.3148\n",
      "2016-12-16 06:15:50.758115 PST | QfOutputMax             43.612\n",
      "2016-12-16 06:15:50.759686 PST | QfOutputMin              0.40583\n",
      "2016-12-16 06:15:50.761096 PST | TargetVfOutputMean      28.2784\n",
      "2016-12-16 06:15:50.763678 PST | TargetVfOutputStd        8.65616\n",
      "2016-12-16 06:15:50.764983 PST | TargetVfOutputMax       37.6618\n",
      "2016-12-16 06:15:50.766572 PST | TargetVfOutputMin        3.20989\n",
      "2016-12-16 06:15:50.769444 PST | RewardsMean              9.30117\n",
      "2016-12-16 06:15:50.770587 PST | RewardsStd               2.54326\n",
      "2016-12-16 06:15:50.771911 PST | RewardsMax              10\n",
      "2016-12-16 06:15:50.773664 PST | RewardsMin               0\n",
      "2016-12-16 06:15:50.775241 PST | ReturnsMean            133.704\n",
      "2016-12-16 06:15:50.777648 PST | ReturnsStd             128.049\n",
      "2016-12-16 06:15:50.779635 PST | ReturnsMax             409.949\n",
      "2016-12-16 06:15:50.780753 PST | ReturnsMin              19.9662\n",
      "2016-12-16 06:15:50.782225 PST | DiscountedReturnsMean  118.801\n",
      "2016-12-16 06:15:50.783789 PST | DiscountedReturnsStd   105.872\n",
      "2016-12-16 06:15:50.785259 PST | DiscountedReturnsMax   337.683\n",
      "2016-12-16 06:15:50.786725 PST | DiscountedReturnsMin    19.8664\n",
      "2016-12-16 06:15:50.788411 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:15:50.790345 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:15:50.791555 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:15:50.793102 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:15:50.794576 PST | TrainingReturnsMean     53.0968\n",
      "2016-12-16 06:15:50.795980 PST | TrainingReturnsStd      38.8412\n",
      "2016-12-16 06:15:50.797328 PST | TrainingReturnsMax     179.968\n",
      "2016-12-16 06:15:50.799089 PST | TrainingReturnsMin       9.98588\n",
      "2016-12-16 06:15:50.801088 PST | ---------------------  ---------\n",
      "2016-12-16 06:15:50.802421 PST | Epoch #9 | Training started\n",
      "2016-12-16 06:16:05.645239 PST | Epoch #9 | Training finished. Time: 14.841318130493164\n",
      "2016-12-16 06:16:05.646653 PST | Epoch #9 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 06:16:33.334374 PST | Epoch #9 | Eval time: 27.687718152999878\n",
      "2016-12-16 06:16:33.338241 PST | ---------------------  ---------\n",
      "2016-12-16 06:16:33.341057 PST | Epoch                    9\n",
      "2016-12-16 06:16:33.343761 PST | AverageReturn           81.7581\n",
      "2016-12-16 06:16:33.348045 PST | QfLoss                  34.1521\n",
      "2016-12-16 06:16:33.353612 PST | YsMean                  32.5291\n",
      "2016-12-16 06:16:33.355210 PST | YsStd                   14.8821\n",
      "2016-12-16 06:16:33.360120 PST | YsMax                   54.0139\n",
      "2016-12-16 06:16:33.362620 PST | YsMin                    0\n",
      "2016-12-16 06:16:33.366119 PST | QfOutputMean            30.5457\n",
      "2016-12-16 06:16:33.368745 PST | QfOutputStd             11.4248\n",
      "2016-12-16 06:16:33.369931 PST | QfOutputMax             50.3273\n",
      "2016-12-16 06:16:33.371703 PST | QfOutputMin              2.44546\n",
      "2016-12-16 06:16:33.373093 PST | TargetVfOutputMean      28.0573\n",
      "2016-12-16 06:16:33.374287 PST | TargetVfOutputStd       10.3584\n",
      "2016-12-16 06:16:33.375771 PST | TargetVfOutputMax       44.467\n",
      "2016-12-16 06:16:33.377389 PST | TargetVfOutputMin        1.38436\n",
      "2016-12-16 06:16:33.379040 PST | RewardsMean              8.90434\n",
      "2016-12-16 06:16:33.380241 PST | RewardsStd               3.11299\n",
      "2016-12-16 06:16:33.382401 PST | RewardsMax               9.99959\n",
      "2016-12-16 06:16:33.384857 PST | RewardsMin               0\n",
      "2016-12-16 06:16:33.386177 PST | ReturnsMean             81.7581\n",
      "2016-12-16 06:16:33.387395 PST | ReturnsStd              47.6368\n",
      "2016-12-16 06:16:33.389285 PST | ReturnsMax             219.938\n",
      "2016-12-16 06:16:33.390710 PST | ReturnsMin              39.9451\n",
      "2016-12-16 06:16:33.392888 PST | DiscountedReturnsMean   77.8612\n",
      "2016-12-16 06:16:33.394818 PST | DiscountedReturnsStd    42.0007\n",
      "2016-12-16 06:16:33.396330 PST | DiscountedReturnsMax   198.316\n",
      "2016-12-16 06:16:33.397599 PST | DiscountedReturnsMin    39.35\n",
      "2016-12-16 06:16:33.398899 PST | PolicyOutputMean         0\n",
      "2016-12-16 06:16:33.400358 PST | PolicyOutputStd          0\n",
      "2016-12-16 06:16:33.401825 PST | PolicyOutputMax          0\n",
      "2016-12-16 06:16:33.403161 PST | PolicyOutputMin          0\n",
      "2016-12-16 06:16:33.404358 PST | TrainingReturnsMean     55.9728\n",
      "2016-12-16 06:16:33.406066 PST | TrainingReturnsStd      38.6039\n",
      "2016-12-16 06:16:33.407756 PST | TrainingReturnsMax     139.981\n",
      "2016-12-16 06:16:33.409848 PST | TrainingReturnsMin       9.98066\n",
      "2016-12-16 06:16:33.412070 PST | ---------------------  ---------\n"
     ]
    }
   ],
   "source": [
    "algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "a_dim = qf.action_dim\n",
    "o_dim = qf.observation_dim\n",
    "o_high = env.spec.action_space.high[0]\n",
    "o_low = env.spec.action_space.low[0]\n",
    "print(a_dim)\n",
    "print(o_dim)\n",
    "print(o_high)\n",
    "print(o_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot QF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAF5CAYAAAC83HEwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ2CRJEmdZ2CRJEmd9/8Bw47Jdms+8igAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127bdb908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_actions = 10000\n",
    "\n",
    "actions = np.linspace(-1, 1, num_actions)\n",
    "actions = np.expand_dims(actions, axis=1)\n",
    "random_state_single = np.random.rand(1, o_dim)\n",
    "random_state = np.vstack([random_state_single for _ in range(num_actions)])\n",
    "\n",
    "feed_dict = {\n",
    "    qf.action_input: actions,\n",
    "    qf.observation_input: random_state,\n",
    "}\n",
    "qf_output = qf.sess.run(\n",
    "    qf.output,\n",
    "    feed_dict=feed_dict\n",
    ")\n",
    "\n",
    "plt.plot(actions, qf_output)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('QF output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect correctness of this quadratic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeedForwardCritic' object has no attribute '_internal_qf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-43633fd3b850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m L_params, L, implicit_policy_output = qf.sess.run(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_qf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_qf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicit_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeedForwardCritic' object has no attribute '_internal_qf'"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    qf.action_input: actions,\n",
    "    qf.observation_input: random_state,\n",
    "}\n",
    "L_params, L, implicit_policy_output = qf.sess.run(\n",
    "    [qf._internal_qf.L_params.output, qf._internal_qf.L, qf.implicit_policy.output],\n",
    "    feed_dict=feed_dict\n",
    ")\n",
    "\n",
    "expected_values = -0.5 * ((actions - implicit_policy_output) * L[0][0][0])**2\n",
    "plt.plot(actions, expected_values)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Expected QF output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-361c34a666b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_values\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Action'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QF output error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expected_values' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(actions, np.abs(expected_values - qf_output))\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('QF output error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure diagonal values are exponentiated corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c358e95d9fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
     ]
    }
   ],
   "source": [
    "print(L[0])\n",
    "print(np.exp(L_params[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure max action is the one taken by the implicit policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'implicit_policy_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-422ba298e2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqf_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimplicit_policy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'implicit_policy_output' is not defined"
     ]
    }
   ],
   "source": [
    "max_index = np.argmax(qf_output, axis=0)\n",
    "print(actions[max_index])\n",
    "print(implicit_policy_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot implicit policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.43246771  0.84345072 -0.56658289]\n",
      " [-0.997998    0.43246771  0.84345072 -0.56658289]\n",
      " [-0.995996    0.43246771  0.84345072 -0.56658289]\n",
      " ..., \n",
      " [ 0.995996    0.43246771  0.84345072 -0.56658289]\n",
      " [ 0.997998    0.43246771  0.84345072 -0.56658289]\n",
      " [ 1.          0.43246771  0.84345072 -0.56658289]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAF5CAYAAABnZ9sSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c232908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17991664 -1.          0.8455713  -0.51282439]\n",
      " [ 0.17991664 -0.997998    0.8455713  -0.51282439]\n",
      " [ 0.17991664 -0.995996    0.8455713  -0.51282439]\n",
      " ..., \n",
      " [ 0.17991664  0.995996    0.8455713  -0.51282439]\n",
      " [ 0.17991664  0.997998    0.8455713  -0.51282439]\n",
      " [ 0.17991664  1.          0.8455713  -0.51282439]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAF5CAYAAABnZ9sSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d662e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45446781  0.81143553 -1.         -0.65910281]\n",
      " [-0.45446781  0.81143553 -0.997998   -0.65910281]\n",
      " [-0.45446781  0.81143553 -0.995996   -0.65910281]\n",
      " ..., \n",
      " [-0.45446781  0.81143553  0.995996   -0.65910281]\n",
      " [-0.45446781  0.81143553  0.997998   -0.65910281]\n",
      " [-0.45446781  0.81143553  1.         -0.65910281]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8891e07e406c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpolicy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinear_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_changing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8891e07e406c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpolicy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinear_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_changing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/policies/argmax_policy.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Clear adam variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         self.sess.run(tf.initialize_variables(\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 run_metadata):\n\u001b[1;32m    707\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m--> 757\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "o_delta = o_high - o_low\n",
    "for dim_changing in range(4):\n",
    "    num_states = 1000\n",
    "    base_state = np.random.rand(1, o_dim) * o_delta + o_low\n",
    "#     base_state = np.zeros((1, o_dim))\n",
    "    linear_states = np.vstack([base_state for _ in range(num_states)])\n",
    "    linear_states[:, dim_changing] = np.linspace(o_low, o_high, num_states)\n",
    "    print(linear_states)\n",
    "    \n",
    "    policy_output = np.vstack([policy.get_action(state)[0] for state in linear_states])\n",
    "    \n",
    "    plt.plot(linear_states[:, dim_changing], policy_output)\n",
    "    plt.xlabel('State {0} dimension'.format(dim_changing))\n",
    "    plt.ylabel('Policy Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
