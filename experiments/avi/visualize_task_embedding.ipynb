{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.torch.pearl.agent import PEARLAgent\n",
    "from rlkit.torch.torch_rl_algorithm import TorchTrainer\n",
    "from rlkit.data_management.multitask_replay_buffer import ObsDictMultiTaskReplayBuffer\n",
    "from rlkit.misc.roboverse_utils import add_data_to_buffer_multitask_v2, get_buffer_size_multitask\n",
    "from rlkit.torch.sac.policies import GaussianCNNPolicy\n",
    "from rlkit.torch.networks.cnn import CNN, ConcatCNN\n",
    "import roboverse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "gpu_id = 6\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "ptu.set_gpu_mode(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file paths\n",
    "CHECKPOINT = ('/nfs/kun1/users/avi/doodad-output/'\n",
    "             '21-05-26-awac-pearl-image-Widow250PickPlaceMetaTestMultiObjectMultiContainer-v0/'\n",
    "             '21-05-26-awac-pearl-image-Widow250PickPlaceMetaTestMultiObjectMultiContainer-v0'\n",
    "              '_2021_05_26_19_46_16_id000--s0/itr_600000.pt')\n",
    "BUFFER = ('/nfs/kun1/users/avi/scripted_sim_datasets/'\n",
    "          'may26_Widow250PickPlaceMetaTrainMultiObjectMultiContainer-v0_16K_save_all_noise_0.1_2021-05-26T16-12-04/'\n",
    "          'may26_Widow250PickPlaceMetaTrainMultiObjectMultiContainer-v0_16K_save_all_noise_0.1_2021-05-26T16-12-04_16000.npy')\n",
    "ENV = 'Widow250PickPlaceMetaTestMultiObjectMultiContainer-v0'\n",
    "\n",
    "#agent kwargs\n",
    "LATENT_DIM = 5\n",
    "USE_NEXT_OBS_IN_CONTEXT = False\n",
    "_DEBUG_DO_NOT_SQRT = False\n",
    "\n",
    "#context kwargs\n",
    "META_BATCH_SIZE = 4\n",
    "TASK_EMBEDDING_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatCNN(\n",
       "  (hidden_activation): ReLU()\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conv_norm_layers): ModuleList()\n",
       "  (pool_layers): ModuleList(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=2323, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc_norm_layers): ModuleList()\n",
       "  (last_fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_env = roboverse.make(ENV, transpose_image=True)\n",
    "state_observation_dim = expl_env.observation_space.spaces['state'].low.size\n",
    "action_dim = expl_env.action_space.low.size\n",
    "reward_dim = 1\n",
    "cnn_params = dict(\n",
    "        input_width=48,\n",
    "        input_height=48,\n",
    "        input_channels=3,\n",
    "        kernel_sizes=[3, 3, 3],\n",
    "        n_channels=[16, 16, 16],\n",
    "        strides=[1, 1, 1],\n",
    "        hidden_sizes=[1024, 512, 256],\n",
    "        paddings=[1, 1, 1],\n",
    "        pool_type='max2d',\n",
    "        pool_sizes=[2, 2, 1],  # the one at the end means no pool\n",
    "        pool_strides=[2, 2, 1],\n",
    "        pool_paddings=[0, 0, 0],\n",
    "        image_augmentation=True,\n",
    "        image_augmentation_padding=4,\n",
    "    )\n",
    "context_encoder_output_dim = LATENT_DIM * 2\n",
    "cnn_params.update(\n",
    "    added_fc_input_size=state_observation_dim + action_dim + reward_dim,\n",
    "    output_size=context_encoder_output_dim,\n",
    "    hidden_sizes=[256, 256],\n",
    ")\n",
    "context_encoder = ConcatCNN(**cnn_params).to(ptu.device)\n",
    "context_encoder.load_state_dict(checkpoint['trainer/context_encoder'])\n",
    "context_encoder.to(ptu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task_indices = list(range(32))\n",
    "observation_keys = ['image', 'state']\n",
    "with open(BUFFER, 'rb') as fl:\n",
    "    data = np.load(fl, allow_pickle=True)\n",
    "num_transitions = get_buffer_size_multitask(data)\n",
    "max_replay_buffer_size = num_transitions + 10\n",
    "\n",
    "replay_buffer = ObsDictMultiTaskReplayBuffer(\n",
    "    max_replay_buffer_size,\n",
    "    expl_env,\n",
    "    train_task_indices,\n",
    "    use_next_obs_in_context=False,\n",
    "    sparse_rewards=False,\n",
    "    observation_keys=observation_keys\n",
    ")\n",
    "add_data_to_buffer_multitask_v2(data, replay_buffer, observation_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PEARLAgent(\n",
    "    LATENT_DIM,\n",
    "    context_encoder,\n",
    "    None,\n",
    "    None,\n",
    "    obs_keys=observation_keys,\n",
    "    use_next_obs_in_context=USE_NEXT_OBS_IN_CONTEXT,\n",
    "    _debug_do_not_sqrt=_DEBUG_DO_NOT_SQRT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_indices = np.random.choice(\n",
    "    train_task_indices, META_BATCH_SIZE,\n",
    ")\n",
    "contexts = (\n",
    "    replay_buffer.sample_context(\n",
    "    task_indices,\n",
    "    TASK_EMBEDDING_BATCH_SIZE,\n",
    "))\n",
    "task_embeddings = agent.latent_posterior(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization params\n",
    "NUM_TASKS = 3\n",
    "NUM_POINTS_PER_TASK = 100\n",
    "COLORS = ('blue', 'green', 'red', 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_indices = np.random.choice(\n",
    "    train_task_indices, NUM_TASKS,\n",
    ")\n",
    "embeddings = []\n",
    "for i in range(NUM_POINTS_PER_TASK):\n",
    "    contexts = (\n",
    "        replay_buffer.sample_context(\n",
    "        task_indices,\n",
    "        TASK_EMBEDDING_BATCH_SIZE,\n",
    "    ))\n",
    "    task_embeddings = agent.latent_posterior(contexts)\n",
    "    embeddings.append(task_embeddings.rsample().detach().cpu().numpy())\n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)\n",
    "print(\"Task Indices:\", task_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pairs = []\n",
    "for i in range(LATENT_DIM - 1):\n",
    "    for j in range(i+1, LATENT_DIM):\n",
    "        index_pairs.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(15,15))\n",
    "scaling = 10 ** 5\n",
    "print(\"Task Indices:\", task_indices)\n",
    "print(xbounds)\n",
    "\n",
    "for counter, indices in enumerate(index_pairs):\n",
    "    datapoints = [[], []]\n",
    "    for idx, task in enumerate(task_indices):\n",
    "        x = [point[idx, indices[0]] for point in embeddings]\n",
    "        y = [point[idx, indices[1]] for point in embeddings]\n",
    "        axs[counter // 5, counter % 5].scatter(x, y, c=COLORS[idx])\n",
    "        #axs[counter // 5, counter % 5].set_xlabel(str(indices[0]))\n",
    "        #axs[counter // 5, counter % 5].set_ylabel(str(indices[1]))\n",
    "        datapoints[0].append(x) \n",
    "        datapoints[1].append(y)\n",
    "    xbounds = (np.min(datapoints[0]), np.max(datapoints[0]))\n",
    "    ybounds = (np.min(datapoints[1]), np.max(datapoints[1]))\n",
    "    axs[counter // 5, counter % 5].set_xlim(*xbounds)\n",
    "    axs[counter // 5, counter % 5].set_ylim(*ybounds)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "datapoints = embedding_means.reshape((-1, LATENT_DIM)) * scaling\n",
    "pca_points = pca.fit_transform(datapoints)\n",
    "pca_points = pca_points.reshape((NUM_POINTS_PER_TASK, NUM_TASKS, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('scaled')\n",
    "xbounds = (np.min(embedding_means[:, 0]), np.max(embedding_means[:, 0]))\n",
    "ybounds = (np.min(embedding_means[:, 1]), np.max(embedding_means[:, 1]))\n",
    "\n",
    "for idx, task in enumerate(task_indices):\n",
    "    x = [mean[idx, 0]  for mean in embeddings]\n",
    "    y = [mean[idx, 1]  for mean in embeddings]\n",
    "    plt.scatter(x, y, c=COLORS[idx])\n",
    "    plt.xlim(*xbounds)\n",
    "    plt.ylim(*ybounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
