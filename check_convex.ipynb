{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from algos.convex_naf import ConvexNAFAlgorithm\n",
    "from algos.ddpg import DDPG as MyDDPG\n",
    "from qfunctions.convex_naf_qfunction import ConcaveNAF\n",
    "from qfunctions.nn_qfunction import FeedForwardCritic\n",
    "from qfunctions.quadratic_naf_qfunction import QuadraticNAF\n",
    "from qfunctions.quadratic_qf import QuadraticQF\n",
    "from policies.nn_policy import FeedForwardPolicy\n",
    "from rllab.exploration_strategies.ou_strategy import OUStrategy\n",
    "\n",
    "from rllab.envs.box2d.cartpole_env import CartpoleEnv\n",
    "from rllab.envs.normalized_env import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 50\n",
    "EPOCH_LENGTH = 100\n",
    "EVAL_SAMPLES = 100\n",
    "DISCOUNT = 0.99\n",
    "QF_LEARNING_RATE = 1e-3\n",
    "POLICY_LEARNING_RATE = 1e-4\n",
    "BATCH_LEARNING_RATE = 1e-2\n",
    "SOFT_TARGET_TAU = 1e-2\n",
    "REPLAY_POOL_SIZE = 1000000\n",
    "MIN_POOL_SIZE = 256\n",
    "SCALE_REWARD = 1.0\n",
    "QF_WEIGHT_DECAY = 0.01\n",
    "MAX_PATH_LENGTH = 1000\n",
    "N_UPDATES_PER_TIME_STEP = 5\n",
    "\n",
    "QF_TYPE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making SGD optimizer\n",
      "/Users/vitchyr/git/rail-rl/algos/naf.py\n",
      "qf params =\n",
      "['qf/advantage_function/observation_mlp/hidden0/weights:0', 'qf/advantage_function/observation_mlp/hidden0/bias:0', 'qf/advantage_function/observation_mlp/hidden1/weights:0', 'qf/advantage_function/observation_mlp/hidden1/bias:0', 'qf/advantage_function/fusion_mlp/hidden0/weights:0', 'qf/advantage_function/fusion_mlp/hidden0/bias:0', 'qf/advantage_function/fusion_mlp/hidden1/weights:0', 'qf/advantage_function/fusion_mlp/hidden1/bias:0', 'qf/advantage_function/fusion_mlp/output_linear/weights:0', 'qf/advantage_function/fusion_mlp/output_linear/bias:0', 'qf/V_function/hidden0/weights:0', 'qf/V_function/hidden0/bias:0', 'qf/V_function/hidden1/weights:0', 'qf/V_function/hidden1/bias:0', 'qf/V_function/weights:0', 'qf/V_function/bias:0']\n"
     ]
    }
   ],
   "source": [
    "env = normalize(CartpoleEnv())\n",
    "policy_params = dict(\n",
    "    observation_hidden_sizes=(100, 100),\n",
    "    hidden_nonlinearity=tf.nn.relu,\n",
    "    output_nonlinearity=tf.nn.tanh,\n",
    ")\n",
    "algo_params = dict(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    epoch_length=EPOCH_LENGTH,\n",
    "    eval_samples=EVAL_SAMPLES,\n",
    "    discount=DISCOUNT,\n",
    "#     policy_learning_rate=POLICY_LEARNING_RATE,\n",
    "    qf_learning_rate=QF_LEARNING_RATE,\n",
    "    soft_target_tau=SOFT_TARGET_TAU,\n",
    "    replay_pool_size=REPLAY_POOL_SIZE,\n",
    "    min_pool_size=MIN_POOL_SIZE,\n",
    "    scale_reward=SCALE_REWARD,\n",
    "    max_path_length=MAX_PATH_LENGTH,\n",
    "    qf_weight_decay=QF_WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "es = OUStrategy(env_spec=env.spec)\n",
    "\n",
    "optimizer_type = 'sgd'\n",
    "qf = ConcaveNAF(\n",
    "    name_or_scope=\"qf\",\n",
    "    env_spec=env.spec,\n",
    "    optimizer_type=optimizer_type,\n",
    ")\n",
    "algorithm = ConvexNAFAlgorithm(\n",
    "    env,\n",
    "    es,\n",
    "    qf,\n",
    "    **algo_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policy = qf.implicit_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 14:54:48.115318 PST | Populating workers...\n",
      "2016-12-16 14:54:48.117235 PST | Populated\n",
      "2016-12-16 14:54:48.119028 PST | Epoch #0 | Training started\n",
      "2016-12-16 14:54:59.668722 PST | Epoch #0 | Training finished. Time: 11.548182010650635\n",
      "2016-12-16 14:54:59.670187 PST | Epoch #1 | Training started\n",
      "2016-12-16 14:55:13.756191 PST | Epoch #1 | Training finished. Time: 14.08236813545227\n",
      "2016-12-16 14:55:13.757782 PST | Epoch #2 | Training started\n",
      "2016-12-16 14:55:33.327501 PST | Epoch #2 | Training finished. Time: 19.5682110786438\n",
      "2016-12-16 14:55:33.332441 PST | Epoch #2 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 14:56:06.410186 PST | Epoch #2 | Eval time: 33.077747106552124\n",
      "2016-12-16 14:56:06.417072 PST | ---------------------  ----------\n",
      "2016-12-16 14:56:06.421595 PST | Epoch                    2\n",
      "2016-12-16 14:56:06.423059 PST | AverageReturn           89.9448\n",
      "2016-12-16 14:56:06.424423 PST | QfLoss                  17.6724\n",
      "2016-12-16 14:56:06.426926 PST | YsMean                   9.5543\n",
      "2016-12-16 14:56:06.428580 PST | YsStd                    3.1907\n",
      "2016-12-16 14:56:06.430040 PST | YsMax                   11.1195\n",
      "2016-12-16 14:56:06.431260 PST | YsMin                    0\n",
      "2016-12-16 14:56:06.432734 PST | QfOutputMean             7.58234\n",
      "2016-12-16 14:56:06.436189 PST | QfOutputStd              0.766202\n",
      "2016-12-16 14:56:06.437941 PST | QfOutputMax              9.8817\n",
      "2016-12-16 14:56:06.439363 PST | QfOutputMin              6.43683\n",
      "2016-12-16 14:56:06.440636 PST | TargetVfOutputMean       0.599884\n",
      "2016-12-16 14:56:06.442054 PST | TargetVfOutputStd        0.218116\n",
      "2016-12-16 14:56:06.443451 PST | TargetVfOutputMax        1.14978\n",
      "2016-12-16 14:56:06.444950 PST | TargetVfOutputMin        0.343389\n",
      "2016-12-16 14:56:06.446277 PST | RewardsMean              8.99448\n",
      "2016-12-16 14:56:06.447750 PST | RewardsStd               2.99816\n",
      "2016-12-16 14:56:06.449107 PST | RewardsMax               9.99999\n",
      "2016-12-16 14:56:06.450395 PST | RewardsMin               0\n",
      "2016-12-16 14:56:06.451782 PST | ReturnsMean             89.9448\n",
      "2016-12-16 14:56:06.453405 PST | ReturnsStd              35.7688\n",
      "2016-12-16 14:56:06.454781 PST | ReturnsMax             149.938\n",
      "2016-12-16 14:56:06.456197 PST | ReturnsMin              29.9643\n",
      "2016-12-16 14:56:06.458017 PST | DiscountedReturnsMean   85.839\n",
      "2016-12-16 14:56:06.459393 PST | DiscountedReturnsStd    32.9621\n",
      "2016-12-16 14:56:06.460919 PST | DiscountedReturnsMax   139.886\n",
      "2016-12-16 14:56:06.462182 PST | DiscountedReturnsMin    29.6657\n",
      "2016-12-16 14:56:06.463805 PST | PolicyOutputMean         0\n",
      "2016-12-16 14:56:06.465206 PST | PolicyOutputStd          0\n",
      "2016-12-16 14:56:06.466616 PST | PolicyOutputMax          0\n",
      "2016-12-16 14:56:06.468162 PST | PolicyOutputMin          0\n",
      "2016-12-16 14:56:06.469832 PST | TrainingReturnsMean     63.1309\n",
      "2016-12-16 14:56:06.470982 PST | TrainingReturnsStd      41.9135\n",
      "2016-12-16 14:56:06.472429 PST | TrainingReturnsMax     199.841\n",
      "2016-12-16 14:56:06.473879 PST | TrainingReturnsMin       9.98501\n",
      "2016-12-16 14:56:06.475289 PST | ---------------------  ----------\n",
      "2016-12-16 14:56:06.476724 PST | Epoch #3 | Training started\n",
      "2016-12-16 14:56:23.731517 PST | Epoch #3 | Training finished. Time: 17.253359079360962\n",
      "2016-12-16 14:56:23.733214 PST | Epoch #3 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 14:57:13.609910 PST | Epoch #3 | Eval time: 49.87669110298157\n",
      "2016-12-16 14:57:13.613446 PST | ---------------------  ----------\n",
      "2016-12-16 14:57:13.616534 PST | Epoch                    3\n",
      "2016-12-16 14:57:13.618583 PST | AverageReturn          108.837\n",
      "2016-12-16 14:57:13.620067 PST | QfLoss                  14.3364\n",
      "2016-12-16 14:57:13.621509 PST | YsMean                  13.6357\n",
      "2016-12-16 14:57:13.623242 PST | YsStd                    4.14499\n",
      "2016-12-16 14:57:13.625485 PST | YsMax                   16.3586\n",
      "2016-12-16 14:57:13.627711 PST | YsMin                    0\n",
      "2016-12-16 14:57:13.628937 PST | QfOutputMean            13.7147\n",
      "2016-12-16 14:57:13.630946 PST | QfOutputStd              0.996675\n",
      "2016-12-16 14:57:13.633453 PST | QfOutputMax             14.9707\n",
      "2016-12-16 14:57:13.634910 PST | QfOutputMin             10.2689\n",
      "2016-12-16 14:57:13.636588 PST | TargetVfOutputMean       4.93977\n",
      "2016-12-16 14:57:13.638561 PST | TargetVfOutputStd        0.33025\n",
      "2016-12-16 14:57:13.639827 PST | TargetVfOutputMax        6.4381\n",
      "2016-12-16 14:57:13.641581 PST | TargetVfOutputMin        4.3737\n",
      "2016-12-16 14:57:13.642987 PST | RewardsMean              9.15453\n",
      "2016-12-16 14:57:13.645244 PST | RewardsStd               2.77424\n",
      "2016-12-16 14:57:13.651526 PST | RewardsMax              10\n",
      "2016-12-16 14:57:13.653708 PST | RewardsMin               0\n",
      "2016-12-16 14:57:13.655597 PST | ReturnsMean            108.837\n",
      "2016-12-16 14:57:13.657490 PST | ReturnsStd              35.7287\n",
      "2016-12-16 14:57:13.659003 PST | ReturnsMax             159.954\n",
      "2016-12-16 14:57:13.661494 PST | ReturnsMin              39.9605\n",
      "2016-12-16 14:57:13.664674 PST | DiscountedReturnsMean  103.032\n",
      "2016-12-16 14:57:13.670190 PST | DiscountedReturnsStd    32.4619\n",
      "2016-12-16 14:57:13.671854 PST | DiscountedReturnsMax   148.501\n",
      "2016-12-16 14:57:13.673323 PST | DiscountedReturnsMin    39.3652\n",
      "2016-12-16 14:57:13.675084 PST | PolicyOutputMean         0\n",
      "2016-12-16 14:57:13.676830 PST | PolicyOutputStd          0\n",
      "2016-12-16 14:57:13.678822 PST | PolicyOutputMax          0\n",
      "2016-12-16 14:57:13.680592 PST | PolicyOutputMin          0\n",
      "2016-12-16 14:57:13.682250 PST | TrainingReturnsMean     60.6803\n",
      "2016-12-16 14:57:13.683601 PST | TrainingReturnsStd      38.8102\n",
      "2016-12-16 14:57:13.685169 PST | TrainingReturnsMax     159.968\n",
      "2016-12-16 14:57:13.686679 PST | TrainingReturnsMin      19.9651\n",
      "2016-12-16 14:57:13.688024 PST | ---------------------  ----------\n",
      "2016-12-16 14:57:13.689432 PST | Epoch #4 | Training started\n",
      "2016-12-16 14:57:35.967707 PST | Epoch #4 | Training finished. Time: 22.27699303627014\n",
      "2016-12-16 14:57:35.969255 PST | Epoch #4 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 14:58:16.871440 PST | Epoch #4 | Eval time: 40.902178049087524\n",
      "2016-12-16 14:58:16.874882 PST | ---------------------  ---------\n",
      "2016-12-16 14:58:16.877844 PST | Epoch                    4\n",
      "2016-12-16 14:58:16.879851 PST | AverageReturn          121.197\n",
      "2016-12-16 14:58:16.882462 PST | QfLoss                  19.9468\n",
      "2016-12-16 14:58:16.884699 PST | YsMean                  19.5456\n",
      "2016-12-16 14:58:16.886775 PST | YsStd                    5.70316\n",
      "2016-12-16 14:58:16.888783 PST | YsMax                   22.6708\n",
      "2016-12-16 14:58:16.890823 PST | YsMin                    0\n",
      "2016-12-16 14:58:16.893298 PST | QfOutputMean            18.2222\n",
      "2016-12-16 14:58:16.895760 PST | QfOutputStd              2.7942\n",
      "2016-12-16 14:58:16.897613 PST | QfOutputMax             21.111\n",
      "2016-12-16 14:58:16.899410 PST | QfOutputMin              8.9485\n",
      "2016-12-16 14:58:16.901764 PST | TargetVfOutputMean      11.3371\n",
      "2016-12-16 14:58:16.903386 PST | TargetVfOutputStd        1.03992\n",
      "2016-12-16 14:58:16.905043 PST | TargetVfOutputMax       12.8174\n",
      "2016-12-16 14:58:16.906752 PST | TargetVfOutputMin        7.512\n",
      "2016-12-16 14:58:16.908414 PST | RewardsMean              9.23407\n",
      "2016-12-16 14:58:16.911413 PST | RewardsStd               2.65188\n",
      "2016-12-16 14:58:16.913144 PST | RewardsMax              10\n",
      "2016-12-16 14:58:16.915865 PST | RewardsMin               0\n",
      "2016-12-16 14:58:16.918094 PST | ReturnsMean            121.197\n",
      "2016-12-16 14:58:16.919344 PST | ReturnsStd              28.4807\n",
      "2016-12-16 14:58:16.920962 PST | ReturnsMax             159.954\n",
      "2016-12-16 14:58:16.922706 PST | ReturnsMin              69.9327\n",
      "2016-12-16 14:58:16.925358 PST | DiscountedReturnsMean  114.315\n",
      "2016-12-16 14:58:16.926743 PST | DiscountedReturnsStd    25.503\n",
      "2016-12-16 14:58:16.929226 PST | DiscountedReturnsMax   148.502\n",
      "2016-12-16 14:58:16.931063 PST | DiscountedReturnsMin    67.8697\n",
      "2016-12-16 14:58:16.933338 PST | PolicyOutputMean         0\n",
      "2016-12-16 14:58:16.935706 PST | PolicyOutputStd          0\n",
      "2016-12-16 14:58:16.937084 PST | PolicyOutputMax          0\n",
      "2016-12-16 14:58:16.938568 PST | PolicyOutputMin          0\n",
      "2016-12-16 14:58:16.940094 PST | TrainingReturnsMean     49.962\n",
      "2016-12-16 14:58:16.942103 PST | TrainingReturnsStd      20.9094\n",
      "2016-12-16 14:58:16.944802 PST | TrainingReturnsMax      79.9593\n",
      "2016-12-16 14:58:16.950050 PST | TrainingReturnsMin       9.98383\n",
      "2016-12-16 14:58:16.953498 PST | ---------------------  ---------\n",
      "2016-12-16 14:58:16.956812 PST | Epoch #5 | Training started\n",
      "2016-12-16 14:58:37.240303 PST | Epoch #5 | Training finished. Time: 20.27829384803772\n",
      "2016-12-16 14:58:37.243178 PST | Epoch #5 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 14:59:17.341895 PST | Epoch #5 | Eval time: 40.09872007369995\n",
      "2016-12-16 14:59:17.345254 PST | ---------------------  ---------\n",
      "2016-12-16 14:59:17.346923 PST | Epoch                    5\n",
      "2016-12-16 14:59:17.349312 PST | AverageReturn           92.9459\n",
      "2016-12-16 14:59:17.351349 PST | QfLoss                  23.5678\n",
      "2016-12-16 14:59:17.353067 PST | YsMean                  23.7727\n",
      "2016-12-16 14:59:17.354530 PST | YsStd                    8.2798\n",
      "2016-12-16 14:59:17.356352 PST | YsMax                   30.1819\n",
      "2016-12-16 14:59:17.357796 PST | YsMin                    0\n",
      "2016-12-16 14:59:17.359230 PST | QfOutputMean            22.2902\n",
      "2016-12-16 14:59:17.360675 PST | QfOutputStd              5.83136\n",
      "2016-12-16 14:59:17.362240 PST | QfOutputMax             30.3118\n",
      "2016-12-16 14:59:17.363754 PST | QfOutputMin              7.86554\n",
      "2016-12-16 14:59:17.365177 PST | TargetVfOutputMean      16.8335\n",
      "2016-12-16 14:59:17.366809 PST | TargetVfOutputStd        2.99306\n",
      "2016-12-16 14:59:17.368389 PST | TargetVfOutputMax       20.3965\n",
      "2016-12-16 14:59:17.369783 PST | TargetVfOutputMin        9.26062\n",
      "2016-12-16 14:59:17.371115 PST | RewardsMean              9.02388\n",
      "2016-12-16 14:59:17.372641 PST | RewardsStd               2.95905\n",
      "2016-12-16 14:59:17.374135 PST | RewardsMax              10\n",
      "2016-12-16 14:59:17.375416 PST | RewardsMin               0\n",
      "2016-12-16 14:59:17.377997 PST | ReturnsMean             92.9459\n",
      "2016-12-16 14:59:17.379683 PST | ReturnsStd              40.2587\n",
      "2016-12-16 14:59:17.381907 PST | ReturnsMax             159.932\n",
      "2016-12-16 14:59:17.383337 PST | ReturnsMin              29.9609\n",
      "2016-12-16 14:59:17.385325 PST | DiscountedReturnsMean   88.4381\n",
      "2016-12-16 14:59:17.386892 PST | DiscountedReturnsStd    36.7447\n",
      "2016-12-16 14:59:17.388221 PST | DiscountedReturnsMax   148.481\n",
      "2016-12-16 14:59:17.389515 PST | DiscountedReturnsMin    29.6623\n",
      "2016-12-16 14:59:17.391209 PST | PolicyOutputMean         0\n",
      "2016-12-16 14:59:17.392674 PST | PolicyOutputStd          0\n",
      "2016-12-16 14:59:17.394074 PST | PolicyOutputMax          0\n",
      "2016-12-16 14:59:17.395337 PST | PolicyOutputMin          0\n",
      "2016-12-16 14:59:17.397057 PST | TrainingReturnsMean     49.9683\n",
      "2016-12-16 14:59:17.399074 PST | TrainingReturnsStd      41.5784\n",
      "2016-12-16 14:59:17.400497 PST | TrainingReturnsMax     199.954\n",
      "2016-12-16 14:59:17.401789 PST | TrainingReturnsMin       9.98007\n",
      "2016-12-16 14:59:17.403000 PST | ---------------------  ---------\n",
      "2016-12-16 14:59:17.404282 PST | Epoch #6 | Training started\n",
      "2016-12-16 14:59:41.301815 PST | Epoch #6 | Training finished. Time: 23.895966053009033\n",
      "2016-12-16 14:59:41.303270 PST | Epoch #6 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:00:24.615404 PST | Epoch #6 | Eval time: 43.3121280670166\n",
      "2016-12-16 15:00:24.618982 PST | ---------------------  ---------\n",
      "2016-12-16 15:00:24.621173 PST | Epoch                    6\n",
      "2016-12-16 15:00:24.622543 PST | AverageReturn           80.8536\n",
      "2016-12-16 15:00:24.624478 PST | QfLoss                  26.7301\n",
      "2016-12-16 15:00:24.625940 PST | YsMean                  27.281\n",
      "2016-12-16 15:00:24.627444 PST | YsStd                   10.8891\n",
      "2016-12-16 15:00:24.629783 PST | YsMax                   38.7423\n",
      "2016-12-16 15:00:24.631123 PST | YsMin                    0\n",
      "2016-12-16 15:00:24.633779 PST | QfOutputMean            26.3587\n",
      "2016-12-16 15:00:24.635957 PST | QfOutputStd              8.268\n",
      "2016-12-16 15:00:24.637940 PST | QfOutputMax             38.1514\n",
      "2016-12-16 15:00:24.639748 PST | QfOutputMin              4.98993\n",
      "2016-12-16 15:00:24.641247 PST | TargetVfOutputMean      21.5906\n",
      "2016-12-16 15:00:24.643306 PST | TargetVfOutputStd        5.59566\n",
      "2016-12-16 15:00:24.645117 PST | TargetVfOutputMax       29.0454\n",
      "2016-12-16 15:00:24.646658 PST | TargetVfOutputMin        6.88387\n",
      "2016-12-16 15:00:24.648160 PST | RewardsMean              8.8939\n",
      "2016-12-16 15:00:24.649639 PST | RewardsStd               3.12676\n",
      "2016-12-16 15:00:24.650843 PST | RewardsMax               9.99982\n",
      "2016-12-16 15:00:24.652299 PST | RewardsMin               0\n",
      "2016-12-16 15:00:24.653767 PST | ReturnsMean             80.8536\n",
      "2016-12-16 15:00:24.655064 PST | ReturnsStd              27.4554\n",
      "2016-12-16 15:00:24.656253 PST | ReturnsMax             139.942\n",
      "2016-12-16 15:00:24.658053 PST | ReturnsMin              29.9528\n",
      "2016-12-16 15:00:24.659825 PST | DiscountedReturnsMean   77.6953\n",
      "2016-12-16 15:00:24.661258 PST | DiscountedReturnsStd    25.3403\n",
      "2016-12-16 15:00:24.664177 PST | DiscountedReturnsMax   131.201\n",
      "2016-12-16 15:00:24.666561 PST | DiscountedReturnsMin    29.6543\n",
      "2016-12-16 15:00:24.667896 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:00:24.669355 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:00:24.671334 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:00:24.672773 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:00:24.674213 PST | TrainingReturnsMean     51.8401\n",
      "2016-12-16 15:00:24.675737 PST | TrainingReturnsStd      30.8601\n",
      "2016-12-16 15:00:24.677244 PST | TrainingReturnsMax     119.982\n",
      "2016-12-16 15:00:24.678673 PST | TrainingReturnsMin      19.9751\n",
      "2016-12-16 15:00:24.680058 PST | ---------------------  ---------\n",
      "2016-12-16 15:00:24.681503 PST | Epoch #7 | Training started\n",
      "2016-12-16 15:00:52.300184 PST | Epoch #7 | Training finished. Time: 27.616335153579712\n",
      "2016-12-16 15:00:52.302454 PST | Epoch #7 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:01:39.989373 PST | Epoch #7 | Eval time: 47.68776297569275\n",
      "2016-12-16 15:01:39.992710 PST | ---------------------  ---------\n",
      "2016-12-16 15:01:39.994347 PST | Epoch                    7\n",
      "2016-12-16 15:01:39.995987 PST | AverageReturn           85.3994\n",
      "2016-12-16 15:01:39.997464 PST | QfLoss                  27.7461\n",
      "2016-12-16 15:01:39.998865 PST | YsMean                  31.6032\n",
      "2016-12-16 15:01:40.003613 PST | YsStd                   13.0942\n",
      "2016-12-16 15:01:40.006037 PST | YsMax                   44.7054\n",
      "2016-12-16 15:01:40.007433 PST | YsMin                    0\n",
      "2016-12-16 15:01:40.009062 PST | QfOutputMean            29.5735\n",
      "2016-12-16 15:01:40.010660 PST | QfOutputStd             10.7081\n",
      "2016-12-16 15:01:40.012220 PST | QfOutputMax             41.6561\n",
      "2016-12-16 15:01:40.013787 PST | QfOutputMin              2.66947\n",
      "2016-12-16 15:01:40.015742 PST | TargetVfOutputMean      26.4521\n",
      "2016-12-16 15:01:40.017836 PST | TargetVfOutputStd        7.89769\n",
      "2016-12-16 15:01:40.019727 PST | TargetVfOutputMax       35.0613\n",
      "2016-12-16 15:01:40.021243 PST | TargetVfOutputMin        6.9555\n",
      "2016-12-16 15:01:40.022904 PST | RewardsMean              8.94661\n",
      "2016-12-16 15:01:40.026018 PST | RewardsStd               3.06049\n",
      "2016-12-16 15:01:40.028172 PST | RewardsMax               9.99985\n",
      "2016-12-16 15:01:40.029612 PST | RewardsMin               0\n",
      "2016-12-16 15:01:40.032833 PST | ReturnsMean             85.3994\n",
      "2016-12-16 15:01:40.034888 PST | ReturnsStd              36.5104\n",
      "2016-12-16 15:01:40.037489 PST | ReturnsMax             139.936\n",
      "2016-12-16 15:01:40.038985 PST | ReturnsMin               9.98306\n",
      "2016-12-16 15:01:40.040753 PST | DiscountedReturnsMean   81.6244\n",
      "2016-12-16 15:01:40.042854 PST | DiscountedReturnsStd    34.127\n",
      "2016-12-16 15:01:40.044308 PST | DiscountedReturnsMax   131.196\n",
      "2016-12-16 15:01:40.046998 PST | DiscountedReturnsMin     9.98306\n",
      "2016-12-16 15:01:40.049589 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:01:40.053058 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:01:40.054684 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:01:40.056355 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:01:40.058665 PST | TrainingReturnsMean     62.8252\n",
      "2016-12-16 15:01:40.061126 PST | TrainingReturnsStd      27.3596\n",
      "2016-12-16 15:01:40.062688 PST | TrainingReturnsMax     119.959\n",
      "2016-12-16 15:01:40.064093 PST | TrainingReturnsMin      29.9679\n",
      "2016-12-16 15:01:40.065930 PST | ---------------------  ---------\n",
      "2016-12-16 15:01:40.069591 PST | Epoch #8 | Training started\n",
      "2016-12-16 15:02:03.073132 PST | Epoch #8 | Training finished. Time: 22.99535298347473\n",
      "2016-12-16 15:02:03.078914 PST | Epoch #8 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:02:55.873338 PST | Epoch #8 | Eval time: 52.794421911239624\n",
      "2016-12-16 15:02:55.876884 PST | ---------------------  ---------\n",
      "2016-12-16 15:02:55.881370 PST | Epoch                    8\n",
      "2016-12-16 15:02:55.882927 PST | AverageReturn           68.4139\n",
      "2016-12-16 15:02:55.890577 PST | QfLoss                  28.2709\n",
      "2016-12-16 15:02:55.893677 PST | YsMean                  31.7169\n",
      "2016-12-16 15:02:55.895882 PST | YsStd                   15.3989\n",
      "2016-12-16 15:02:55.897275 PST | YsMax                   50.8051\n",
      "2016-12-16 15:02:55.898521 PST | YsMin                    0\n",
      "2016-12-16 15:02:55.901155 PST | QfOutputMean            31.0287\n",
      "2016-12-16 15:02:55.903434 PST | QfOutputStd             12.6009\n",
      "2016-12-16 15:02:55.905827 PST | QfOutputMax             46.4017\n",
      "2016-12-16 15:02:55.908132 PST | QfOutputMin              2.7153\n",
      "2016-12-16 15:02:55.916165 PST | TargetVfOutputMean      28.3044\n",
      "2016-12-16 15:02:55.917537 PST | TargetVfOutputStd       10.5494\n",
      "2016-12-16 15:02:55.919749 PST | TargetVfOutputMax       41.2288\n",
      "2016-12-16 15:02:55.923042 PST | TargetVfOutputMin        3.60315\n",
      "2016-12-16 15:02:55.925650 PST | RewardsMean              8.71942\n",
      "2016-12-16 15:02:55.927131 PST | RewardsStd               3.33246\n",
      "2016-12-16 15:02:55.929531 PST | RewardsMax              10\n",
      "2016-12-16 15:02:55.931422 PST | RewardsMin               0\n",
      "2016-12-16 15:02:55.935085 PST | ReturnsMean             68.4139\n",
      "2016-12-16 15:02:55.937452 PST | ReturnsStd              48.3302\n",
      "2016-12-16 15:02:55.940142 PST | ReturnsMax             209.955\n",
      "2016-12-16 15:02:55.941598 PST | ReturnsMin              19.964\n",
      "2016-12-16 15:02:55.943785 PST | DiscountedReturnsMean   65.3746\n",
      "2016-12-16 15:02:55.945517 PST | DiscountedReturnsStd    43.5959\n",
      "2016-12-16 15:02:55.947138 PST | DiscountedReturnsMax   190.235\n",
      "2016-12-16 15:02:55.950247 PST | DiscountedReturnsMin    19.8642\n",
      "2016-12-16 15:02:55.951573 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:02:55.954101 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:02:55.955442 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:02:55.957572 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:02:55.959107 PST | TrainingReturnsMean     64.5846\n",
      "2016-12-16 15:02:55.960398 PST | TrainingReturnsStd      19.0551\n",
      "2016-12-16 15:02:55.962908 PST | TrainingReturnsMax     109.966\n",
      "2016-12-16 15:02:55.964545 PST | TrainingReturnsMin      39.9773\n",
      "2016-12-16 15:02:55.967901 PST | ---------------------  ---------\n",
      "2016-12-16 15:02:55.969652 PST | Epoch #9 | Training started\n",
      "2016-12-16 15:03:23.998072 PST | Epoch #9 | Training finished. Time: 28.027148962020874\n",
      "2016-12-16 15:03:23.999335 PST | Epoch #9 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:04:16.735704 PST | Epoch #9 | Eval time: 52.736371994018555\n",
      "2016-12-16 15:04:16.739900 PST | ---------------------  ---------\n",
      "2016-12-16 15:04:16.741149 PST | Epoch                    9\n",
      "2016-12-16 15:04:16.742625 PST | AverageReturn           74.1078\n",
      "2016-12-16 15:04:16.744136 PST | QfLoss                  27.8862\n",
      "2016-12-16 15:04:16.745507 PST | YsMean                  35.2925\n",
      "2016-12-16 15:04:16.747377 PST | YsStd                   16.9683\n",
      "2016-12-16 15:04:16.750116 PST | YsMax                   56.2428\n",
      "2016-12-16 15:04:16.751895 PST | YsMin                    0\n",
      "2016-12-16 15:04:16.753465 PST | QfOutputMean            34.8484\n",
      "2016-12-16 15:04:16.755855 PST | QfOutputStd             13.4486\n",
      "2016-12-16 15:04:16.758647 PST | QfOutputMax             52.0194\n",
      "2016-12-16 15:04:16.760378 PST | QfOutputMin              4.357\n",
      "2016-12-16 15:04:16.762294 PST | TargetVfOutputMean      32.033\n",
      "2016-12-16 15:04:16.764356 PST | TargetVfOutputStd       11.96\n",
      "2016-12-16 15:04:16.767177 PST | TargetVfOutputMax       46.7216\n",
      "2016-12-16 15:04:16.768531 PST | TargetVfOutputMin        3.8115\n",
      "2016-12-16 15:04:16.770639 PST | RewardsMean              8.80489\n",
      "2016-12-16 15:04:16.772677 PST | RewardsStd               3.23311\n",
      "2016-12-16 15:04:16.774572 PST | RewardsMax               9.99944\n",
      "2016-12-16 15:04:16.776357 PST | RewardsMin               0\n",
      "2016-12-16 15:04:16.778251 PST | ReturnsMean             74.1078\n",
      "2016-12-16 15:04:16.781142 PST | ReturnsStd              27.2207\n",
      "2016-12-16 15:04:16.782643 PST | ReturnsMax             129.94\n",
      "2016-12-16 15:04:16.784848 PST | ReturnsMin              29.9513\n",
      "2016-12-16 15:04:16.786583 PST | DiscountedReturnsMean   71.4274\n",
      "2016-12-16 15:04:16.789853 PST | DiscountedReturnsStd    25.2309\n",
      "2016-12-16 15:04:16.791445 PST | DiscountedReturnsMax   122.423\n",
      "2016-12-16 15:04:16.794379 PST | DiscountedReturnsMin    29.6529\n",
      "2016-12-16 15:04:16.796270 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:04:16.798087 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:04:16.799441 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:04:16.801401 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:04:16.803342 PST | TrainingReturnsMean     57.294\n",
      "2016-12-16 15:04:16.805484 PST | TrainingReturnsStd      32.1355\n",
      "2016-12-16 15:04:16.807577 PST | TrainingReturnsMax     139.956\n",
      "2016-12-16 15:04:16.809277 PST | TrainingReturnsMin      19.9701\n",
      "2016-12-16 15:04:16.812450 PST | ---------------------  ---------\n",
      "2016-12-16 15:04:16.814723 PST | Epoch #10 | Training started\n",
      "2016-12-16 15:04:47.777746 PST | Epoch #10 | Training finished. Time: 30.961166858673096\n",
      "2016-12-16 15:04:47.780071 PST | Epoch #10 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:05:59.984500 PST | Epoch #10 | Eval time: 72.20453691482544\n",
      "2016-12-16 15:05:59.989924 PST | ---------------------  ----------\n",
      "2016-12-16 15:05:59.991723 PST | Epoch                   10\n",
      "2016-12-16 15:05:59.993346 PST | AverageReturn           82.4488\n",
      "2016-12-16 15:05:59.995852 PST | QfLoss                  34.104\n",
      "2016-12-16 15:05:59.998021 PST | YsMean                  36.7775\n",
      "2016-12-16 15:05:59.999607 PST | YsStd                   18.4941\n",
      "2016-12-16 15:06:00.002332 PST | YsMax                   57.9662\n",
      "2016-12-16 15:06:00.004359 PST | YsMin                    0\n",
      "2016-12-16 15:06:00.006821 PST | QfOutputMean            33.8665\n",
      "2016-12-16 15:06:00.009234 PST | QfOutputStd             15.7577\n",
      "2016-12-16 15:06:00.012003 PST | QfOutputMax             51.5453\n",
      "2016-12-16 15:06:00.013703 PST | QfOutputMin              0.897776\n",
      "2016-12-16 15:06:00.016322 PST | TargetVfOutputMean      33.351\n",
      "2016-12-16 15:06:00.017603 PST | TargetVfOutputStd       14.4262\n",
      "2016-12-16 15:06:00.019002 PST | TargetVfOutputMax       48.4541\n",
      "2016-12-16 15:06:00.021284 PST | TargetVfOutputMin        2.35786\n",
      "2016-12-16 15:06:00.023070 PST | RewardsMean              8.91338\n",
      "2016-12-16 15:06:00.025750 PST | RewardsStd               3.10325\n",
      "2016-12-16 15:06:00.027268 PST | RewardsMax              10\n",
      "2016-12-16 15:06:00.029219 PST | RewardsMin               0\n",
      "2016-12-16 15:06:00.031064 PST | ReturnsMean             82.4488\n",
      "2016-12-16 15:06:00.032736 PST | ReturnsStd              60.8427\n",
      "2016-12-16 15:06:00.036203 PST | ReturnsMax             249.95\n",
      "2016-12-16 15:06:00.037877 PST | ReturnsMin              29.9528\n",
      "2016-12-16 15:06:00.039622 PST | DiscountedReturnsMean   77.8536\n",
      "2016-12-16 15:06:00.042056 PST | DiscountedReturnsStd    53.8127\n",
      "2016-12-16 15:06:00.044352 PST | DiscountedReturnsMax   222.139\n",
      "2016-12-16 15:06:00.045739 PST | DiscountedReturnsMin    29.6543\n",
      "2016-12-16 15:06:00.047416 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:06:00.048950 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:06:00.050965 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:06:00.052884 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:06:00.054315 PST | TrainingReturnsMean     61.3862\n",
      "2016-12-16 15:06:00.055666 PST | TrainingReturnsStd      22.9164\n",
      "2016-12-16 15:06:00.057014 PST | TrainingReturnsMax     109.898\n",
      "2016-12-16 15:06:00.058391 PST | TrainingReturnsMin      29.9639\n",
      "2016-12-16 15:06:00.059717 PST | ---------------------  ----------\n",
      "2016-12-16 15:06:00.060993 PST | Epoch #11 | Training started\n",
      "2016-12-16 15:06:39.369471 PST | Epoch #11 | Training finished. Time: 39.30711603164673\n",
      "2016-12-16 15:06:39.372929 PST | Epoch #11 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:07:34.209257 PST | Epoch #11 | Eval time: 54.8363299369812\n",
      "2016-12-16 15:07:34.212018 PST | ---------------------  ----------\n",
      "2016-12-16 15:07:34.213346 PST | Epoch                   11\n",
      "2016-12-16 15:07:34.215063 PST | AverageReturn           89.9515\n",
      "2016-12-16 15:07:34.216338 PST | QfLoss                  21.3873\n",
      "2016-12-16 15:07:34.217865 PST | YsMean                  37.1807\n",
      "2016-12-16 15:07:34.218911 PST | YsStd                   18.8698\n",
      "2016-12-16 15:07:34.220714 PST | YsMax                   60.2397\n",
      "2016-12-16 15:07:34.222389 PST | YsMin                    0\n",
      "2016-12-16 15:07:34.224177 PST | QfOutputMean            34.4917\n",
      "2016-12-16 15:07:34.225727 PST | QfOutputStd             16.2906\n",
      "2016-12-16 15:07:34.227798 PST | QfOutputMax             53.5883\n",
      "2016-12-16 15:07:34.229159 PST | QfOutputMin             -0.790391\n",
      "2016-12-16 15:07:34.230730 PST | TargetVfOutputMean      33.5548\n",
      "2016-12-16 15:07:34.232136 PST | TargetVfOutputStd       15.4812\n",
      "2016-12-16 15:07:34.233585 PST | TargetVfOutputMax       50.8453\n",
      "2016-12-16 15:07:34.235020 PST | TargetVfOutputMin       -0.222521\n",
      "2016-12-16 15:07:34.236484 PST | RewardsMean              8.99515\n",
      "2016-12-16 15:07:34.239376 PST | RewardsStd               2.99839\n",
      "2016-12-16 15:07:34.241298 PST | RewardsMax              10\n",
      "2016-12-16 15:07:34.243212 PST | RewardsMin               0\n",
      "2016-12-16 15:07:34.244617 PST | ReturnsMean             89.9515\n",
      "2016-12-16 15:07:34.245704 PST | ReturnsStd              53.2916\n",
      "2016-12-16 15:07:34.246927 PST | ReturnsMax             229.95\n",
      "2016-12-16 15:07:34.248173 PST | ReturnsMin              39.9543\n",
      "2016-12-16 15:07:34.249537 PST | DiscountedReturnsMean   85.1638\n",
      "2016-12-16 15:07:34.251031 PST | DiscountedReturnsStd    46.9121\n",
      "2016-12-16 15:07:34.252279 PST | DiscountedReturnsMax   206.345\n",
      "2016-12-16 15:07:34.253514 PST | DiscountedReturnsMin    39.3592\n",
      "2016-12-16 15:07:34.254796 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:07:34.256032 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:07:34.257053 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:07:34.258124 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:07:34.259844 PST | TrainingReturnsMean     58.6332\n",
      "2016-12-16 15:07:34.260785 PST | TrainingReturnsStd      41.2746\n",
      "2016-12-16 15:07:34.261952 PST | TrainingReturnsMax     129.947\n",
      "2016-12-16 15:07:34.263113 PST | TrainingReturnsMin       9.98477\n",
      "2016-12-16 15:07:34.264230 PST | ---------------------  ----------\n",
      "2016-12-16 15:07:34.265384 PST | Epoch #12 | Training started\n",
      "2016-12-16 15:08:10.203773 PST | Epoch #12 | Training finished. Time: 35.93705081939697\n",
      "2016-12-16 15:08:10.205566 PST | Epoch #12 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:09:13.376084 PST | Epoch #12 | Eval time: 63.170511960983276\n",
      "2016-12-16 15:09:13.380229 PST | ---------------------  ---------\n",
      "2016-12-16 15:09:13.382031 PST | Epoch                   12\n",
      "2016-12-16 15:09:13.384228 PST | AverageReturn           89.9461\n",
      "2016-12-16 15:09:13.385504 PST | QfLoss                  35.8981\n",
      "2016-12-16 15:09:13.388494 PST | YsMean                  40.4378\n",
      "2016-12-16 15:09:13.390370 PST | YsStd                   20.6824\n",
      "2016-12-16 15:09:13.392486 PST | YsMax                   64.1902\n",
      "2016-12-16 15:09:13.395173 PST | YsMin                    0\n",
      "2016-12-16 15:09:13.397389 PST | QfOutputMean            37.3627\n",
      "2016-12-16 15:09:13.398862 PST | QfOutputStd             17.5538\n",
      "2016-12-16 15:09:13.400333 PST | QfOutputMax             56.1601\n",
      "2016-12-16 15:09:13.403134 PST | QfOutputMin             -2.11883\n",
      "2016-12-16 15:09:13.404787 PST | TargetVfOutputMean      37.0566\n",
      "2016-12-16 15:09:13.406921 PST | TargetVfOutputStd       16.7038\n",
      "2016-12-16 15:09:13.408578 PST | TargetVfOutputMax       54.7432\n",
      "2016-12-16 15:09:13.410232 PST | TargetVfOutputMin       -1.30606\n",
      "2016-12-16 15:09:13.413053 PST | RewardsMean              8.99461\n",
      "2016-12-16 15:09:13.414884 PST | RewardsStd               2.99821\n",
      "2016-12-16 15:09:13.416729 PST | RewardsMax              10\n",
      "2016-12-16 15:09:13.419174 PST | RewardsMin               0\n",
      "2016-12-16 15:09:13.420606 PST | ReturnsMean             89.9461\n",
      "2016-12-16 15:09:13.422978 PST | ReturnsStd              57.2701\n",
      "2016-12-16 15:09:13.424493 PST | ReturnsMax             199.945\n",
      "2016-12-16 15:09:13.425897 PST | ReturnsMin              29.9579\n",
      "2016-12-16 15:09:13.427329 PST | DiscountedReturnsMean   84.9448\n",
      "2016-12-16 15:09:13.428635 PST | DiscountedReturnsStd    51.2558\n",
      "2016-12-16 15:09:13.430369 PST | DiscountedReturnsMax   182.047\n",
      "2016-12-16 15:09:13.431892 PST | DiscountedReturnsMin    29.6594\n",
      "2016-12-16 15:09:13.433163 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:09:13.435275 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:09:13.437311 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:09:13.438736 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:09:13.441771 PST | TrainingReturnsMean     57.824\n",
      "2016-12-16 15:09:13.443331 PST | TrainingReturnsStd      27.2911\n",
      "2016-12-16 15:09:13.445794 PST | TrainingReturnsMax     119.926\n",
      "2016-12-16 15:09:13.447951 PST | TrainingReturnsMin      29.957\n",
      "2016-12-16 15:09:13.449554 PST | ---------------------  ---------\n",
      "2016-12-16 15:09:13.452333 PST | Epoch #13 | Training started\n",
      "2016-12-16 15:09:51.342631 PST | Epoch #13 | Training finished. Time: 37.88756203651428\n",
      "2016-12-16 15:09:51.343979 PST | Epoch #13 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:11:24.699228 PST | Epoch #13 | Eval time: 93.35523414611816\n",
      "2016-12-16 15:11:24.701613 PST | ---------------------  ----------\n",
      "2016-12-16 15:11:24.703024 PST | Epoch                   13\n",
      "2016-12-16 15:11:24.707088 PST | AverageReturn          114.952\n",
      "2016-12-16 15:11:24.710099 PST | QfLoss                  29.3562\n",
      "2016-12-16 15:11:24.713069 PST | YsMean                  43.3133\n",
      "2016-12-16 15:11:24.714704 PST | YsStd                   20.6388\n",
      "2016-12-16 15:11:24.716242 PST | YsMax                   64.0574\n",
      "2016-12-16 15:11:24.719483 PST | YsMin                    0\n",
      "2016-12-16 15:11:24.721967 PST | QfOutputMean            39.9078\n",
      "2016-12-16 15:11:24.724961 PST | QfOutputStd             18.4138\n",
      "2016-12-16 15:11:24.726927 PST | QfOutputMax             57.5127\n",
      "2016-12-16 15:11:24.729558 PST | QfOutputMin             -1.38705\n",
      "2016-12-16 15:11:24.732502 PST | TargetVfOutputMean      38.8219\n",
      "2016-12-16 15:11:24.733893 PST | TargetVfOutputStd       17.0113\n",
      "2016-12-16 15:11:24.736286 PST | TargetVfOutputMax       54.6051\n",
      "2016-12-16 15:11:24.740172 PST | TargetVfOutputMin       -0.185157\n",
      "2016-12-16 15:11:24.744030 PST | RewardsMean              9.19614\n",
      "2016-12-16 15:11:24.745735 PST | RewardsStd               2.7118\n",
      "2016-12-16 15:11:24.747374 PST | RewardsMax              10\n",
      "2016-12-16 15:11:24.749828 PST | RewardsMin               0\n",
      "2016-12-16 15:11:24.753341 PST | ReturnsMean            114.952\n",
      "2016-12-16 15:11:24.755817 PST | ReturnsStd              80.8975\n",
      "2016-12-16 15:11:24.758656 PST | ReturnsMax             279.954\n",
      "2016-12-16 15:11:24.761338 PST | ReturnsMin              29.9563\n",
      "2016-12-16 15:11:24.763697 PST | DiscountedReturnsMean  106.219\n",
      "2016-12-16 15:11:24.766099 PST | DiscountedReturnsStd    70.3886\n",
      "2016-12-16 15:11:24.768305 PST | DiscountedReturnsMax   245.245\n",
      "2016-12-16 15:11:24.771076 PST | DiscountedReturnsMin    29.6578\n",
      "2016-12-16 15:11:24.774061 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:11:24.776344 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:11:24.778503 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:11:24.780516 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:11:24.783729 PST | TrainingReturnsMean     61.3914\n",
      "2016-12-16 15:11:24.786367 PST | TrainingReturnsStd      31.586\n",
      "2016-12-16 15:11:24.828038 PST | TrainingReturnsMax     139.966\n",
      "2016-12-16 15:11:24.830339 PST | TrainingReturnsMin      19.9682\n",
      "2016-12-16 15:11:24.832933 PST | ---------------------  ----------\n",
      "2016-12-16 15:11:24.847045 PST | Epoch #14 | Training started\n",
      "2016-12-16 15:12:04.933292 PST | Epoch #14 | Training finished. Time: 40.07957100868225\n",
      "2016-12-16 15:12:04.934395 PST | Epoch #14 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:13:26.851048 PST | Epoch #14 | Eval time: 81.91663885116577\n",
      "2016-12-16 15:13:26.861488 PST | ---------------------  ---------\n",
      "2016-12-16 15:13:26.876279 PST | Epoch                   14\n",
      "2016-12-16 15:13:26.879004 PST | AverageReturn           80.7812\n",
      "2016-12-16 15:13:26.881652 PST | QfLoss                  37.089\n",
      "2016-12-16 15:13:26.884582 PST | YsMean                  39.812\n",
      "2016-12-16 15:13:26.889873 PST | YsStd                   21.7521\n",
      "2016-12-16 15:13:26.892804 PST | YsMax                   68.0921\n",
      "2016-12-16 15:13:26.894347 PST | YsMin                    0\n",
      "2016-12-16 15:13:26.898636 PST | QfOutputMean            37.7033\n",
      "2016-12-16 15:13:26.902286 PST | QfOutputStd             18.5507\n",
      "2016-12-16 15:13:26.906955 PST | QfOutputMax             60.4146\n",
      "2016-12-16 15:13:26.910784 PST | QfOutputMin             -2.79029\n",
      "2016-12-16 15:13:26.914055 PST | TargetVfOutputMean      37.3824\n",
      "2016-12-16 15:13:26.917015 PST | TargetVfOutputStd       18.0238\n",
      "2016-12-16 15:13:26.920628 PST | TargetVfOutputMax       58.6869\n",
      "2016-12-16 15:13:26.923232 PST | TargetVfOutputMin       -2.33175\n",
      "2016-12-16 15:13:26.925668 PST | RewardsMean              8.89335\n",
      "2016-12-16 15:13:26.929316 PST | RewardsStd               3.12803\n",
      "2016-12-16 15:13:26.932300 PST | RewardsMax              10\n",
      "2016-12-16 15:13:26.933689 PST | RewardsMin               0\n",
      "2016-12-16 15:13:26.936116 PST | ReturnsMean             80.7812\n",
      "2016-12-16 15:13:26.938983 PST | ReturnsStd              50.4055\n",
      "2016-12-16 15:13:26.943794 PST | ReturnsMax             179.939\n",
      "2016-12-16 15:13:26.946513 PST | ReturnsMin              19.9678\n",
      "2016-12-16 15:13:26.957367 PST | DiscountedReturnsMean   76.8095\n",
      "2016-12-16 15:13:26.959348 PST | DiscountedReturnsStd    45.8904\n",
      "2016-12-16 15:13:26.962721 PST | DiscountedReturnsMax   165.433\n",
      "2016-12-16 15:13:26.964000 PST | DiscountedReturnsMin    19.8679\n",
      "2016-12-16 15:13:26.965155 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:13:26.966441 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:13:26.968056 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:13:26.969357 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:13:26.970982 PST | TrainingReturnsMean     90.9492\n",
      "2016-12-16 15:13:26.972394 PST | TrainingReturnsStd      52.2241\n",
      "2016-12-16 15:13:26.973927 PST | TrainingReturnsMax     209.946\n",
      "2016-12-16 15:13:26.975866 PST | TrainingReturnsMin      19.9795\n",
      "2016-12-16 15:13:26.978395 PST | ---------------------  ---------\n",
      "2016-12-16 15:13:26.980202 PST | Epoch #15 | Training started\n",
      "2016-12-16 15:14:11.347337 PST | Epoch #15 | Training finished. Time: 44.36548590660095\n",
      "2016-12-16 15:14:11.351415 PST | Epoch #15 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:15:35.357726 PST | Epoch #15 | Eval time: 84.00633382797241\n",
      "2016-12-16 15:15:35.362487 PST | ---------------------  ---------\n",
      "2016-12-16 15:15:35.365063 PST | Epoch                   15\n",
      "2016-12-16 15:15:35.367877 PST | AverageReturn           70.7128\n",
      "2016-12-16 15:15:35.369337 PST | QfLoss                  21.5159\n",
      "2016-12-16 15:15:35.371663 PST | YsMean                  36.3392\n",
      "2016-12-16 15:15:35.373064 PST | YsStd                   22.2178\n",
      "2016-12-16 15:15:35.374523 PST | YsMax                   69.1085\n",
      "2016-12-16 15:15:35.376046 PST | YsMin                    0\n",
      "2016-12-16 15:15:35.377926 PST | QfOutputMean            36.4565\n",
      "2016-12-16 15:15:35.380263 PST | QfOutputStd             19.9588\n",
      "2016-12-16 15:15:35.381907 PST | QfOutputMax             62.3344\n",
      "2016-12-16 15:15:35.383755 PST | QfOutputMin             -2.03294\n",
      "2016-12-16 15:15:35.385193 PST | TargetVfOutputMean      34.8949\n",
      "2016-12-16 15:15:35.387901 PST | TargetVfOutputStd       19.5164\n",
      "2016-12-16 15:15:35.389289 PST | TargetVfOutputMax       59.7159\n",
      "2016-12-16 15:15:35.391089 PST | TargetVfOutputMin       -2.48362\n",
      "2016-12-16 15:15:35.392602 PST | RewardsMean              8.75492\n",
      "2016-12-16 15:15:35.394284 PST | RewardsStd               3.29102\n",
      "2016-12-16 15:15:35.395814 PST | RewardsMax              10\n",
      "2016-12-16 15:15:35.398436 PST | RewardsMin               0\n",
      "2016-12-16 15:15:35.400002 PST | ReturnsMean             70.7128\n",
      "2016-12-16 15:15:35.402524 PST | ReturnsStd              31.7315\n",
      "2016-12-16 15:15:35.404188 PST | ReturnsMax             129.944\n",
      "2016-12-16 15:15:35.405665 PST | ReturnsMin              29.9528\n",
      "2016-12-16 15:15:35.407831 PST | DiscountedReturnsMean   68.1293\n",
      "2016-12-16 15:15:35.409387 PST | DiscountedReturnsStd    29.5103\n",
      "2016-12-16 15:15:35.410798 PST | DiscountedReturnsMax   122.428\n",
      "2016-12-16 15:15:35.413618 PST | DiscountedReturnsMin    29.6544\n",
      "2016-12-16 15:15:35.415511 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:15:35.417198 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:15:35.419766 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:15:35.421260 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:15:35.422940 PST | TrainingReturnsMean     75.7942\n",
      "2016-12-16 15:15:35.424324 PST | TrainingReturnsStd      39.6682\n",
      "2016-12-16 15:15:35.426204 PST | TrainingReturnsMax     189.959\n",
      "2016-12-16 15:15:35.427590 PST | TrainingReturnsMin      39.9683\n",
      "2016-12-16 15:15:35.428936 PST | ---------------------  ---------\n",
      "2016-12-16 15:15:35.431304 PST | Epoch #16 | Training started\n",
      "2016-12-16 15:16:14.516322 PST | Epoch #16 | Training finished. Time: 39.0826940536499\n",
      "2016-12-16 15:16:14.517381 PST | Epoch #16 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:17:33.118454 PST | Epoch #16 | Eval time: 78.6010639667511\n",
      "2016-12-16 15:17:33.120876 PST | ---------------------  ---------\n",
      "2016-12-16 15:17:33.122216 PST | Epoch                   16\n",
      "2016-12-16 15:17:33.123907 PST | AverageReturn           80.7795\n",
      "2016-12-16 15:17:33.125938 PST | QfLoss                  28.6192\n",
      "2016-12-16 15:17:33.127618 PST | YsMean                  39.8979\n",
      "2016-12-16 15:17:33.130140 PST | YsStd                   23.1119\n",
      "2016-12-16 15:17:33.131814 PST | YsMax                   68.5418\n",
      "2016-12-16 15:17:33.134308 PST | YsMin                    0\n",
      "2016-12-16 15:17:33.135909 PST | QfOutputMean            37.9922\n",
      "2016-12-16 15:17:33.137769 PST | QfOutputStd             20.2357\n",
      "2016-12-16 15:17:33.139356 PST | QfOutputMax             60.766\n",
      "2016-12-16 15:17:33.142188 PST | QfOutputMin             -4.92593\n",
      "2016-12-16 15:17:33.145410 PST | TargetVfOutputMean      37.6773\n",
      "2016-12-16 15:17:33.147610 PST | TargetVfOutputStd       19.8452\n",
      "2016-12-16 15:17:33.149105 PST | TargetVfOutputMax       59.134\n",
      "2016-12-16 15:17:33.151476 PST | TargetVfOutputMin       -4.17103\n",
      "2016-12-16 15:17:33.153136 PST | RewardsMean              8.89315\n",
      "2016-12-16 15:17:33.155429 PST | RewardsStd               3.12796\n",
      "2016-12-16 15:17:33.157271 PST | RewardsMax               9.99978\n",
      "2016-12-16 15:17:33.158836 PST | RewardsMin               0\n",
      "2016-12-16 15:17:33.160629 PST | ReturnsMean             80.7795\n",
      "2016-12-16 15:17:33.162783 PST | ReturnsStd              39.0382\n",
      "2016-12-16 15:17:33.164451 PST | ReturnsMax             169.944\n",
      "2016-12-16 15:17:33.165982 PST | ReturnsMin              19.9684\n",
      "2016-12-16 15:17:33.168854 PST | DiscountedReturnsMean   77.272\n",
      "2016-12-16 15:17:33.170475 PST | DiscountedReturnsStd    35.8045\n",
      "2016-12-16 15:17:33.172142 PST | DiscountedReturnsMax   157.007\n",
      "2016-12-16 15:17:33.174335 PST | DiscountedReturnsMin    19.8686\n",
      "2016-12-16 15:17:33.175982 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:17:33.177918 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:17:33.180374 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:17:33.181785 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:17:33.183205 PST | TrainingReturnsMean     55.9563\n",
      "2016-12-16 15:17:33.184804 PST | TrainingReturnsStd      41.2523\n",
      "2016-12-16 15:17:33.186658 PST | TrainingReturnsMax     179.859\n",
      "2016-12-16 15:17:33.188266 PST | TrainingReturnsMin       9.98151\n",
      "2016-12-16 15:17:33.189835 PST | ---------------------  ---------\n",
      "2016-12-16 15:17:33.192279 PST | Epoch #17 | Training started\n",
      "2016-12-16 15:18:07.422997 PST | Epoch #17 | Training finished. Time: 34.22903800010681\n",
      "2016-12-16 15:18:07.424503 PST | Epoch #17 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-16 15:19:27.387859 PST | Epoch #17 | Eval time: 79.96335005760193\n",
      "2016-12-16 15:19:27.390767 PST | ---------------------  ---------\n",
      "2016-12-16 15:19:27.393820 PST | Epoch                   17\n",
      "2016-12-16 15:19:27.396865 PST | AverageReturn           91.946\n",
      "2016-12-16 15:19:27.398838 PST | QfLoss                  50.4195\n",
      "2016-12-16 15:19:27.401705 PST | YsMean                  44.8098\n",
      "2016-12-16 15:19:27.403025 PST | YsStd                   23.1641\n",
      "2016-12-16 15:19:27.404840 PST | YsMax                   69.1925\n",
      "2016-12-16 15:19:27.407494 PST | YsMin                    0\n",
      "2016-12-16 15:19:27.409437 PST | QfOutputMean            41.1257\n",
      "2016-12-16 15:19:27.411256 PST | QfOutputStd             18.8797\n",
      "2016-12-16 15:19:27.414613 PST | QfOutputMax             59.3209\n",
      "2016-12-16 15:19:27.420913 PST | QfOutputMin             -2.69206\n",
      "2016-12-16 15:19:27.425342 PST | TargetVfOutputMean      41.9041\n",
      "2016-12-16 15:19:27.429123 PST | TargetVfOutputStd       18.8416\n",
      "2016-12-16 15:19:27.430787 PST | TargetVfOutputMax       59.7957\n",
      "2016-12-16 15:19:27.432595 PST | TargetVfOutputMin       -2.76976\n",
      "2016-12-16 15:19:27.436332 PST | RewardsMean              9.01431\n",
      "2016-12-16 15:19:27.438984 PST | RewardsStd               2.97193\n",
      "2016-12-16 15:19:27.440730 PST | RewardsMax              10\n",
      "2016-12-16 15:19:27.442188 PST | RewardsMin               0\n",
      "2016-12-16 15:19:27.444433 PST | ReturnsMean             91.946\n",
      "2016-12-16 15:19:27.446624 PST | ReturnsStd              66.9001\n",
      "2016-12-16 15:19:27.448097 PST | ReturnsMax             269.946\n",
      "2016-12-16 15:19:27.450789 PST | ReturnsMin              19.9727\n",
      "2016-12-16 15:19:27.453195 PST | DiscountedReturnsMean   86.2767\n",
      "2016-12-16 15:19:27.454956 PST | DiscountedReturnsStd    58.224\n",
      "2016-12-16 15:19:27.456505 PST | DiscountedReturnsMax   237.613\n",
      "2016-12-16 15:19:27.458087 PST | DiscountedReturnsMin    19.8728\n",
      "2016-12-16 15:19:27.460236 PST | PolicyOutputMean         0\n",
      "2016-12-16 15:19:27.462490 PST | PolicyOutputStd          0\n",
      "2016-12-16 15:19:27.464172 PST | PolicyOutputMax          0\n",
      "2016-12-16 15:19:27.466523 PST | PolicyOutputMin          0\n",
      "2016-12-16 15:19:27.468718 PST | TrainingReturnsMean     65.3461\n",
      "2016-12-16 15:19:27.470759 PST | TrainingReturnsStd      39.9197\n",
      "2016-12-16 15:19:27.472401 PST | TrainingReturnsMax     179.926\n",
      "2016-12-16 15:19:27.474466 PST | TrainingReturnsMin      29.9539\n",
      "2016-12-16 15:19:27.476388 PST | ---------------------  ---------\n",
      "2016-12-16 15:19:27.478800 PST | Epoch #18 | Training started\n",
      "2016-12-16 15:20:13.910999 PST | Epoch #18 | Training finished. Time: 46.43065690994263\n",
      "2016-12-16 15:20:13.912701 PST | Epoch #18 | Collecting samples for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[#########                     ] | ETA: 00:00:31"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ed6a1a5ed49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/online_algorithm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_eval_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes_path_returns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes_path_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_epoch_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/algos/convex_naf.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, epoch, es_path_returns)\u001b[0m\n\u001b[1;32m     42\u001b[0m         paths = self.eval_sampler.obtain_samples(\n\u001b[1;32m     43\u001b[0m             \u001b[0mitr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_eval_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rllab-private/sandbox/rocky/tf/samplers/batch_sampler.py\u001b[0m in \u001b[0;36mobtain_samples\u001b[0;34m(self, itr, batch_size)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mmax_path_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_path_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhole_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rllab-private/rllab/sampler/parallel_sampler.py\u001b[0m in \u001b[0;36msample_paths\u001b[0;34m(policy_params, max_samples, max_path_length, env_params, scope)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_path_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mshow_prog_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rllab-private/rllab/sampler/stateful_pool.py\u001b[0m in \u001b[0;36mrun_collect\u001b[0;34m(self, collect_once, threshold, args, show_prog_bar)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgBarCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rllab-private/rllab/sampler/parallel_sampler.py\u001b[0m in \u001b[0;36m_worker_collect_one_path\u001b[0;34m(G, max_path_length, scope)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_worker_collect_one_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_path_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_scoped_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_path_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rewards\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rllab-private/rllab/sampler/utils.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(env, agent, max_path_length, animated, speedup)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mpath_length\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_path_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mnext_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/policies/argmax_policy.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Clear adam variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         self.sess.run(tf.initialize_variables(\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         ))\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_update_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "a_dim = qf.action_dim\n",
    "o_dim = qf.observation_dim\n",
    "o_high = env.spec.action_space.high[0]\n",
    "o_low = env.spec.action_space.low[0]\n",
    "print(a_dim)\n",
    "print(o_dim)\n",
    "print(o_high)\n",
    "print(o_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot QF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(201, 200), (200, 200), (200, 1)]\n"
     ]
    }
   ],
   "source": [
    "params = algorithm.sess.run(qf.update_weights_ops)\n",
    "print([p.shape for p in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAF5CAYAAAC4KaENAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niyRJKo3/D5aX8wi8Gn3eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cae80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_actions = 100\n",
    "\n",
    "actions = np.linspace(-1000, 1000, num_actions)\n",
    "actions = np.expand_dims(actions, axis=1)\n",
    "random_state_single = np.random.rand(1, o_dim)\n",
    "random_state = np.vstack([random_state_single for _ in range(num_actions)])\n",
    "\n",
    "feed_dict = {\n",
    "    qf.action_input: actions,\n",
    "    qf.observation_input: random_state,\n",
    "}\n",
    "qf_output = qf.sess.run(\n",
    "    qf.output,\n",
    "    feed_dict=feed_dict\n",
    ")\n",
    "\n",
    "# plt.plot(np.tanh(actions), qf_output)\n",
    "plt.plot(actions, qf_output)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('QF output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect correctness of this quadratic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeedForwardCritic' object has no attribute '_internal_qf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-43633fd3b850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m L_params, L, implicit_policy_output = qf.sess.run(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_qf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_qf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicit_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeedForwardCritic' object has no attribute '_internal_qf'"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    qf.action_input: actions,\n",
    "    qf.observation_input: random_state,\n",
    "}\n",
    "L_params, L, implicit_policy_output = qf.sess.run(\n",
    "    [qf._internal_qf.L_params.output, qf._internal_qf.L, qf.implicit_policy.output],\n",
    "    feed_dict=feed_dict\n",
    ")\n",
    "\n",
    "expected_values = -0.5 * ((actions - implicit_policy_output) * L[0][0][0])**2\n",
    "plt.plot(actions, expected_values)\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Expected QF output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-361c34a666b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_values\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mqf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Action'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QF output error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'expected_values' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(actions, np.abs(expected_values - qf_output))\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('QF output error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure diagonal values are exponentiated corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c358e95d9fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
     ]
    }
   ],
   "source": [
    "print(L[0])\n",
    "print(np.exp(L_params[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure max action is the one taken by the implicit policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'implicit_policy_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-422ba298e2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqf_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimplicit_policy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'implicit_policy_output' is not defined"
     ]
    }
   ],
   "source": [
    "max_index = np.argmax(qf_output, axis=0)\n",
    "print(actions[max_index])\n",
    "print(implicit_policy_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot implicit policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.43246771  0.84345072 -0.56658289]\n",
      " [-0.997998    0.43246771  0.84345072 -0.56658289]\n",
      " [-0.995996    0.43246771  0.84345072 -0.56658289]\n",
      " ..., \n",
      " [ 0.995996    0.43246771  0.84345072 -0.56658289]\n",
      " [ 0.997998    0.43246771  0.84345072 -0.56658289]\n",
      " [ 1.          0.43246771  0.84345072 -0.56658289]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAF5CAYAAABnZ9sSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c232908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17991664 -1.          0.8455713  -0.51282439]\n",
      " [ 0.17991664 -0.997998    0.8455713  -0.51282439]\n",
      " [ 0.17991664 -0.995996    0.8455713  -0.51282439]\n",
      " ..., \n",
      " [ 0.17991664  0.995996    0.8455713  -0.51282439]\n",
      " [ 0.17991664  0.997998    0.8455713  -0.51282439]\n",
      " [ 0.17991664  1.          0.8455713  -0.51282439]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAF5CAYAAABnZ9sSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d662e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45446781  0.81143553 -1.         -0.65910281]\n",
      " [-0.45446781  0.81143553 -0.997998   -0.65910281]\n",
      " [-0.45446781  0.81143553 -0.995996   -0.65910281]\n",
      " ..., \n",
      " [-0.45446781  0.81143553  0.995996   -0.65910281]\n",
      " [-0.45446781  0.81143553  0.997998   -0.65910281]\n",
      " [-0.45446781  0.81143553  1.         -0.65910281]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8891e07e406c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpolicy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinear_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_changing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-8891e07e406c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpolicy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinear_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_changing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/git/rail-rl/policies/argmax_policy.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Clear adam variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         self.sess.run(tf.initialize_variables(\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 run_metadata):\n\u001b[1;32m    707\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[0;32m/Users/vitchyr/anaconda/envs/rllab3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m--> 757\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "o_delta = o_high - o_low\n",
    "for dim_changing in range(4):\n",
    "    num_states = 1000\n",
    "    base_state = np.random.rand(1, o_dim) * o_delta + o_low\n",
    "#     base_state = np.zeros((1, o_dim))\n",
    "    linear_states = np.vstack([base_state for _ in range(num_states)])\n",
    "    linear_states[:, dim_changing] = np.linspace(o_low, o_high, num_states)\n",
    "    print(linear_states)\n",
    "    \n",
    "    policy_output = np.vstack([policy.get_action(state)[0] for state in linear_states])\n",
    "    \n",
    "    plt.plot(linear_states[:, dim_changing], policy_output)\n",
    "    plt.xlabel('State {0} dimension'.format(dim_changing))\n",
    "    plt.ylabel('Policy Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
